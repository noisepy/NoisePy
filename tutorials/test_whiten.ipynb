{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PIA2IaqUOeOA"
   },
   "source": [
    "# Welcome to the NoisePy SCEDC Tutorial!\n",
    "\n",
    "Noisepy is a python software package to process ambient seismic noise cross correlations. \n",
    "\n",
    "**Publication about this software**:\n",
    "Chengxin Jiang, Marine A. Denolle; NoisePy: A New High‐Performance Python Tool for Ambient‐Noise Seismology. Seismological Research Letters 2020; 91 (3): 1853–1866. doi: https://doi.org/10.1785/0220190364\n",
    "\n",
    "\n",
    "\n",
    "This tutorial will walk you through the basic steps of using NoisePy to compute ambient noise cross correlation functions using single instance workflow.\n",
    "\n",
    "The data is stored on AWS S3 as the SCEDC Data Set: https://scedc.caltech.edu/data/getstarted-pds.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we install the noisepy-seis package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this line if the environment doesn't have noisepy already installed:\n",
    "# ! pip install noisepy-seis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Warning__: NoisePy uses ```obspy``` as a core Python module to manipulate seismic data. Restart the runtime now for proper installation of ```obspy``` on Colab."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "FaKuajVCOo2r"
   },
   "source": [
    "This tutorial should be ran after installing the noisepy package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtDb2_y3Oreg"
   },
   "source": [
    "## Import necessary modules\n",
    "\n",
    "Then we import the basic modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vceZgD83PnNc"
   },
   "outputs": [],
   "source": [
    "from noisepy.seis import cross_correlate, stack, plotting_modules, __version__       # noisepy core functions\n",
    "from noisepy.seis.asdfstore import ASDFCCStore, ASDFStackStore          # Object to store ASDF data within noisepy\n",
    "from noisepy.seis.scedc_s3store import SCEDCS3DataStore, channel_filter # Object to query SCEDC data from on S3\n",
    "from noisepy.seis.datatypes import ConfigParameters                     # Main configuration object\n",
    "from noisepy.seis.channelcatalog import XMLStationChannelCatalog        # Required stationXML handling object\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetimerange import DateTimeRange\n",
    "from noisepy.seis.noise_module import whiten, whiten_1D, whiten_1D\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "print(f\"Using NoisePy version {__version__}\")\n",
    "\n",
    "path = \"./scedc_data\" \n",
    "\n",
    "os.makedirs(path, exist_ok=True)\n",
    "cc_data_path = os.path.join(path, \"CCF\")\n",
    "stack_data_path = os.path.join(path, \"STACK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pntYzIYGNTn8"
   },
   "source": [
    "We will work with a single day worth of data on SCEDC. The continuous data is organized with a single day and channel per miniseed (https://scedc.caltech.edu/data/cloud.html). For this example, you can choose any year since 2002. We will just cross correlate a single day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yojR0Z3ALm6K"
   },
   "outputs": [],
   "source": [
    "# SCEDC S3 bucket common URL characters for that day.\n",
    "S3_DATA = \"s3://scedc-pds/continuous_waveforms/\"\n",
    "# timeframe for analysis\n",
    "start = datetime(2002, 1, 2)\n",
    "end = datetime(2002, 1, 4)\n",
    "range = DateTimeRange(start, end)\n",
    "print(range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1CC-BljNzus"
   },
   "source": [
    "The station information, including the instrumental response, is stored as stationXML in the following bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhfgrMPALsYS"
   },
   "outputs": [],
   "source": [
    "S3_STATION_XML = \"s3://scedc-pds/FDSNstationXML/CI/\"            # S3 storage of stationXML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssaL5fa5IhI7"
   },
   "source": [
    "## Ambient Noise Project Configuration\n",
    "\n",
    "We store the metadata information about the ambient noise cross correlation workflow in a ConfigParameters() object. We first initialize it, then we tune the parameters for this cross correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIjBD7riIfdJ"
   },
   "outputs": [],
   "source": [
    "# Initialize ambient noise workflow configuration\n",
    "config = ConfigParameters() # default config parameters which can be customized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tsp7RfC8IwE-"
   },
   "source": [
    "Customize the job parameters below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ByEiHRjmIAPB"
   },
   "outputs": [],
   "source": [
    "\n",
    "config.samp_freq= 20  # (int) Sampling rate in Hz of desired processing (it can be different than the data sampling rate)\n",
    "config.cc_len= 3600.0  # (float) basic unit of data length for fft (sec)\n",
    "    # criteria for data selection\n",
    "config.ncomp = 3  # 1 or 3 component data (needed to decide whether do rotation)\n",
    "\n",
    "\n",
    "config.acorr_only = False  # only perform auto-correlation or not\n",
    "config.xcorr_only = True  # only perform cross-correlation or not\n",
    "\n",
    "# config.inc_hours = 24 # if the data is first \n",
    "\n",
    " # pre-processing parameters\n",
    "config.step= 1800.0  # (float) overlapping between each cc_len (sec)\n",
    "config.stationxml= False  # station.XML file used to remove instrument response for SAC/miniseed data\n",
    "config.rm_resp= \"inv\"  # select 'no' to not remove response and use 'inv' if you use the stationXML,'spectrum',\n",
    "config.freqmin = 0.05\n",
    "config.freqmax = 10.0\n",
    "config.max_over_std  = 10  # threshold to remove window of bad signals: set it to 10*9 if prefer not to remove them\n",
    "\n",
    "# TEMPORAL and SPECTRAL NORMALISATION\n",
    "config.freq_norm= \"rma\"  # choose between \"rma\" for a soft whitenning or \"no\" for no whitening. Pure whitening is not implemented correctly at this point.\n",
    "config.smoothspect_N = 10  # moving window length to smooth spectrum amplitude (points)\n",
    "    # here, choose smoothspect_N for the case of a strict whitening (e.g., phase_only)\n",
    "\n",
    "config.time_norm = \"no\"  # 'no' for no normalization, or 'rma', 'one_bit' for normalization in time domain,\n",
    "    # TODO: change time_norm option from \"no\" to \"None\"\n",
    "config.smooth_N= 10  # moving window length for time domain normalization if selected (points)\n",
    "\n",
    "config.cc_method= \"xcorr\"  # 'xcorr' for pure cross correlation OR 'deconv' for deconvolution;\n",
    "    # FOR \"COHERENCY\" PLEASE set freq_norm to \"rma\", time_norm to \"no\" and cc_method to \"xcorr\"\n",
    "\n",
    "# OUTPUTS:\n",
    "config.substack = True  # True = smaller stacks within the time chunk. False: it will stack over inc_hours\n",
    "config.substack_len = config.cc_len  # how long to stack over (for monitoring purpose): need to be multiples of cc_len\n",
    "    # if substack=True, substack_len=2*cc_len, then you pre-stack every 2 correlation windows.\n",
    "    # for instance: substack=True, substack_len=cc_len means that you keep ALL of the correlations\n",
    "\n",
    "config.maxlag= 200  # lags of cross-correlation to save (sec)\n",
    "config.substack = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this tutorial make sure the previous run is empty\n",
    "os.system(f\"rm -rf {cc_data_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wwv1QCQhP_0Y"
   },
   "source": [
    "## Step 1: Cross-correlation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jq2DKIS9Rl2H"
   },
   "outputs": [],
   "source": [
    "\n",
    "stations = \"SBC,RIO,DEV\".split(\",\") # filter to these stations\n",
    "catalog = XMLStationChannelCatalog(S3_STATION_XML)\n",
    "raw_store = SCEDCS3DataStore(S3_DATA, catalog, channel_filter(stations, \"BH\"), range) # Store for reading raw data from S3 bucket\n",
    "cc_store = ASDFCCStore(cc_data_path) # Store for writing CC data\n",
    "\n",
    "# print the configuration parameters. Some are chosen by default but we can modify them\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one time series from the raw_store\n",
    "\n",
    "span = raw_store.get_timespans()\n",
    "channels = raw_store.get_channels(span[0])\n",
    "d = raw_store.read_data(span[0], channels[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = d.data.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "    # delta = fft_para[\"dt\"]\n",
    "    # freqmin = fft_para[\"freqmin\"]\n",
    "    # freqmax = fft_para[\"freqmax\"]\n",
    "    # smooth_N = fft_para[\"smooth_N\"]\n",
    "    # freq_norm = fft_para[\"freq_norm\"]\n",
    "\n",
    "fft_para = {\"dt\": 1/d.sampling_rate, \"freqmin\": config.freqmin, \"freqmax\": config.freqmax, \"smooth_N\": config.smoothspect_N, \"freq_norm\": config.freq_norm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.fftpack import next_fast_len\n",
    "import time \n",
    "\n",
    "from noisepy.seis.noise_module import moving_ave, whiten, moving_ave_2D\n",
    "\n",
    "\n",
    "def whiten_original(data, fft_para):\n",
    "    \"\"\"\n",
    "    This function takes 1-dimensional timeseries array, transforms to frequency domain using fft,\n",
    "    whitens the amplitude of the spectrum in frequency domain between *freqmin* and *freqmax*\n",
    "    and returns the whitened fft.\n",
    "    PARAMETERS:\n",
    "    ----------------------\n",
    "    data: numpy.ndarray contains the 1D time series to whiten\n",
    "    fft_para: dict containing all fft_cc parameters such as\n",
    "        dt: The sampling space of the `data`\n",
    "        freqmin: The lower frequency bound\n",
    "        freqmax: The upper frequency bound\n",
    "        smooth_N: integer, it defines the half window length to smooth\n",
    "        freq_norm: whitening method between 'one-bit' and 'RMA'\n",
    "    RETURNS:\n",
    "    ----------------------\n",
    "    FFTRawSign: numpy.ndarray contains the FFT of the whitened input trace between the frequency bounds\n",
    "    \"\"\"\n",
    "\n",
    "    # load parameters\n",
    "    delta = fft_para[\"dt\"]\n",
    "    freqmin = fft_para[\"freqmin\"]\n",
    "    freqmax = fft_para[\"freqmax\"]\n",
    "    smooth_N = fft_para[\"smooth_N\"]\n",
    "    freq_norm = fft_para[\"freq_norm\"]\n",
    "\n",
    "    # Speed up FFT by padding to optimal size for FFTPACK\n",
    "    if data.ndim == 1:\n",
    "        axis = 0\n",
    "    elif data.ndim == 2:\n",
    "        axis = 1\n",
    "\n",
    "    Nfft = int(next_fast_len(int(data.shape[axis])))\n",
    "    print(\"Nfft\",Nfft)\n",
    "    Napod = 1000\n",
    "    Nfft = int(Nfft)\n",
    "    freqVec = scipy.fftpack.fftfreq(Nfft, d=delta)[: Nfft // 2]\n",
    "    print(len(freqVec))\n",
    "    J = np.where((freqVec >= freqmin) & (freqVec <= freqmax))[0]\n",
    "    print(J[0])\n",
    "    low = J[0] - Napod\n",
    "    if low <= 0:\n",
    "        low = 1\n",
    "\n",
    "    left = J[0]\n",
    "    right = J[-1]\n",
    "    high = J[-1] + Napod\n",
    "    if high > Nfft / 2:\n",
    "        high = len(freqVec)-1 #int(Nfft // 2)\n",
    "        print(len(freqVec)-1)\n",
    "        print(int(Nfft//2))\n",
    "\n",
    "    print(\"the 4 corners of the butterworth filter\")\n",
    "    print(low, left, right, high)\n",
    "    print(len(freqVec))\n",
    "    print(freqVec[low], freqVec[left], freqVec[right], freqVec[high])\n",
    "    FFTRawSign = scipy.fftpack.fft(data, Nfft, axis=axis)\n",
    "    print(FFTRawSign.shape)\n",
    "    # Left tapering:\n",
    "    if axis == 1:\n",
    "        FFTRawSign[:, 0:low] *= 0\n",
    "        FFTRawSign[:, low:left] = np.cos(np.linspace(np.pi / 2.0, np.pi, left - low)) ** 2 * np.exp(\n",
    "            1j * np.angle(FFTRawSign[:, low:left])\n",
    "        )\n",
    "        # Pass band:\n",
    "        if freq_norm == \"phase_only\":\n",
    "            FFTRawSign[:, left:right] = np.exp(1j * np.angle(FFTRawSign[:, left:right]))\n",
    "        elif freq_norm == \"rma\":\n",
    "            for ii in range(data.shape[0]):\n",
    "                tave = moving_ave(np.abs(FFTRawSign[ii, left:right]), smooth_N)\n",
    "                FFTRawSign[ii, left:right] = FFTRawSign[ii, left:right] / tave\n",
    "        # Right tapering:\n",
    "        FFTRawSign[:, right:high] = np.cos(np.linspace(0.0, np.pi / 2.0, high - right)) ** 2 * np.exp(\n",
    "            1j * np.angle(FFTRawSign[:, right:high])\n",
    "        )\n",
    "        FFTRawSign[:, high : Nfft // 2] *= 0\n",
    "\n",
    "        # Hermitian symmetry (because the input is real)\n",
    "        FFTRawSign[:, -(Nfft // 2) + 1 :] = np.flip(np.conj(FFTRawSign[:, 1 : (Nfft // 2)]), axis=axis)\n",
    "    else:\n",
    "        FFTRawSign[0:low] *= 0\n",
    "        FFTRawSign[low:left] = np.cos(np.linspace(np.pi / 2.0, np.pi, left - low)) ** 2 * np.exp(\n",
    "            1j * np.angle(FFTRawSign[low:left])\n",
    "        )\n",
    "        # Pass band:\n",
    "        if freq_norm == \"phase_only\":\n",
    "            FFTRawSign[left:right] = np.exp(1j * np.angle(FFTRawSign[left:right]))\n",
    "        elif freq_norm == \"rma\":\n",
    "            tave = moving_ave(np.abs(FFTRawSign[left:right]), smooth_N)\n",
    "            FFTRawSign[left:right] = FFTRawSign[left:right] / tave\n",
    "        # Right tapering:\n",
    "        FFTRawSign[right:high] = np.cos(np.linspace(0.0, np.pi / 2.0, high - right)) ** 2 * np.exp(\n",
    "            1j * np.angle(FFTRawSign[right:high])\n",
    "        )\n",
    "        FFTRawSign[high : Nfft // 2] *= 0\n",
    "\n",
    "        # Hermitian symmetry (because the input is real)\n",
    "        FFTRawSign[-(Nfft // 2) + 1 :] = FFTRawSign[1 : (Nfft // 2)].conjugate()[::-1]\n",
    "\n",
    "    return FFTRawSign\n",
    "\n",
    "\n",
    "# def whiten(data, fft_para, n_taper=1000):\n",
    "    \"\"\"\n",
    "    This function takes a timeseries array, transforms to frequency domain using fft,\n",
    "    whitens the amplitude of the spectrum in frequency domain between *freqmin* and *freqmax*\n",
    "    and returns the whitened fft.\n",
    "    PARAMETERS:\n",
    "    ----------------------\n",
    "    data: numpy.ndarray contains the 1D time series to whiten\n",
    "    fft_para: dict containing all fft_cc parameters such as\n",
    "        dt: The sampling space of the `data`\n",
    "        freqmin: The lower frequency bound\n",
    "        freqmax: The upper frequency bound\n",
    "        smooth_N: integer, it defines the half window length to smooth\n",
    "        freq_norm: whitening method between 'one-bit' and 'RMA'\n",
    "    RETURNS:\n",
    "    ----------------------\n",
    "    FFTRawSign: numpy.ndarray contains the FFT of the whitened input trace between the frequency bounds\n",
    "    \"\"\"\n",
    "\n",
    "    # Speed up FFT by padding to optimal size for FFTPACK\n",
    "    if data.ndim == 1:\n",
    "        FFTRawSign = whiten_1D(data, fft_para, n_taper)\n",
    "        # ARR_OUT: Only for consistency with noisepy approach of holding the full\n",
    "        # spectrum (not just 0 and positive freq. part)\n",
    "        arr_out = np.zeros((FFTRawSign.shape[0] - 1) * 2 + 1, dtype=complex)\n",
    "        arr_out[0 : FFTRawSign.shape[0]] = FFTRawSign\n",
    "        arr_out[FFTRawSign.shape[0] :] = FFTRawSign[1:].conjugate()[::-1]\n",
    "\n",
    "    elif data.ndim == 2:\n",
    "        FFTRawSign = whiten_2D(data, fft_para, n_taper)\n",
    "        arr_out = np.zeros((FFTRawSign.shape[0], (FFTRawSign.shape[1] - 1) * 2 + 1), dtype=complex)\n",
    "        arr_out[:, FFTRawSign.shape[1] :] = FFTRawSign[:, 1:].conjugate()[::-1]\n",
    "    return FFTRawSign\n",
    "\n",
    "\n",
    "\n",
    "# def whiten_1D(timeseries, fft_para, n_taper):\n",
    "#     \"\"\"\n",
    "#     This function takes a 1-dimensional timeseries array, transforms to frequency domain using fft,\n",
    "#     whitens the amplitude of the spectrum in frequency domain between *freqmin* and *freqmax*\n",
    "#     and returns the whitened fft.\n",
    "#     PARAMETERS:\n",
    "#     ----------------------\n",
    "#     data: numpy.ndarray contains the 1D time series to whiten\n",
    "#     fft_para: dict containing all fft_cc parameters such as\n",
    "#         dt: The sampling space of the `data`\n",
    "#         freqmin: The lower frequency bound\n",
    "#         freqmax: The upper frequency bound\n",
    "#         smooth_N: integer, it defines the half window length to smooth\n",
    "#         n_taper, optional: integer, define the width of the taper in samples\n",
    "#     RETURNS:\n",
    "#     ----------------------\n",
    "#     FFTRawSign: numpy.ndarray contains the FFT of the whitened input trace between the frequency bounds\n",
    "#     \"\"\"\n",
    "#     # load parameters\n",
    "#     delta = fft_para[\"dt\"]\n",
    "#     freqmin = fft_para[\"freqmin\"]\n",
    "#     freqmax = fft_para[\"freqmax\"]\n",
    "#     smooth_N = fft_para[\"smoothspect_N\"]\n",
    "#     print(\"whitening in 1D\")\n",
    "\n",
    "#     nfft = next_fast_len(len(timeseries))\n",
    "#     spec = np.fft.fft(timeseries, nfft)\n",
    "#     freq = np.fft.fftfreq(nfft, d=delta)\n",
    "\n",
    "#     ix0 = np.argmin(np.abs(freq - freqmin))\n",
    "#     ix1 = np.argmin(np.abs(freq - freqmax))\n",
    "\n",
    "#     if ix1 + n_taper > nfft:\n",
    "#         ix11 = nfft\n",
    "#     else:\n",
    "#         ix11 = ix1 + n_taper\n",
    "\n",
    "#     if ix0 - n_taper < 0:\n",
    "#         ix00 = 0\n",
    "#     else:\n",
    "#         ix00 = ix0 - n_taper\n",
    "\n",
    "#     print(ix00, ix0, ix1, ix11)\n",
    "#     spec_out = spec.copy()\n",
    "#     spec_out[0:ix00] = 0.0 + 0.0j\n",
    "#     spec_out[ix11:] = 0.0 + 0.0j\n",
    "#     del spec\n",
    "\n",
    "#     if smooth_N <= 1:\n",
    "#         spec_out[ix00:ix11] = np.exp(1.0j * np.angle(spec_out[ix00:ix11]))\n",
    "#     else:\n",
    "#         spec_out[ix00:ix11] /= moving_ave(np.abs(spec_out[ix00:ix11]), smooth_N)\n",
    "\n",
    "#     x = np.linspace(np.pi / 2.0, np.pi, ix0 - ix00)\n",
    "#     spec_out[ix00:ix0] *= np.cos(x) ** 2\n",
    "\n",
    "#     x = np.linspace(0.0, np.pi / 2.0, ix11 - ix1)\n",
    "#     spec_out[ix1:ix11] *= np.cos(x) ** 2\n",
    "\n",
    "#     return spec_out\n",
    "\n",
    "\n",
    "# def whiten_2D(timeseries, fft_para, n_taper):\n",
    "    \"\"\"\n",
    "    This function takes a 2-dimensional timeseries array, transforms to frequency domain using fft,\n",
    "    whitens the amplitude of the spectrum in frequency domain between *freqmin* and *freqmax*\n",
    "    and returns the whitened fft.\n",
    "    PARAMETERS:\n",
    "    ----------------------\n",
    "    data: numpy.ndarray contains the 1D time series to whiten\n",
    "    fft_para: dict containing all fft_cc parameters such as\n",
    "        dt: The sampling space of the `data`\n",
    "        freqmin: The lower frequency bound\n",
    "        freqmax: The upper frequency bound\n",
    "        smooth_N: integer, it defines the half window length to smooth\n",
    "        n_taper, optional: integer, define the width of the taper in samples\n",
    "    RETURNS:\n",
    "    ----------------------\n",
    "    FFTRawSign: numpy.ndarray contains the FFT of the whitened input trace between the frequency bounds\n",
    "    \"\"\"\n",
    "    # load parameters\n",
    "    delta = fft_para[\"dt\"]\n",
    "    freqmin = fft_para[\"freqmin\"]\n",
    "    freqmax = fft_para[\"freqmax\"]\n",
    "    smooth_N = fft_para[\"smooth_N\"]\n",
    "\n",
    "    nfft = next_fast_len(timeseries.shape[1])\n",
    "    spec = np.fft.fftn(timeseries, s=[nfft])\n",
    "    freq = np.fft.fftfreq(nfft, d=delta)\n",
    "\n",
    "    ix0 = np.argmin(np.abs(freq - freqmin))\n",
    "    ix1 = np.argmin(np.abs(freq - freqmax))\n",
    "\n",
    "    if ix1 + n_taper > nfft:\n",
    "        ix11 = nfft\n",
    "    else:\n",
    "        ix11 = ix1 + n_taper\n",
    "\n",
    "    if ix0 - n_taper < 0:\n",
    "        ix00 = 0\n",
    "    else:\n",
    "        ix00 = ix0 - n_taper\n",
    "\n",
    "    spec_out = spec.copy()  # may be inconvenient due to higher memory usage\n",
    "    spec_out[:, 0:ix00] = 0.0 + 0.0j\n",
    "    spec_out[:, ix11:] = 0.0 + 0.0j\n",
    "\n",
    "    if smooth_N <= 1:\n",
    "        spec_out[:, ix00:ix11] = np.exp(1.0j * np.angle(spec_out[:, ix00:ix11]))\n",
    "    else:\n",
    "        spec_out[:, ix00:ix11] /= moving_ave_2D(np.abs(spec_out[:, ix00:ix11]), smooth_N)\n",
    "\n",
    "    x = np.linspace(np.pi / 2.0, np.pi, ix0 - ix00)\n",
    "    spec_out[:, ix00:ix0] *= np.cos(x) ** 2\n",
    "\n",
    "    x = np.linspace(0.0, np.pi / 2.0, ix11 - ix1)\n",
    "    spec_out[:, ix1:ix11] *= np.cos(x) ** 2\n",
    "\n",
    "    return spec_out\n",
    "\n",
    "# test case:\n",
    "# the non-smoothed version of whitening needs to return the same as the original version.\n",
    "# it is not expected that the smoothed version returns the same, so currently no test for that\n",
    "# (would be good to add one based on some expected outcome)\n",
    "\n",
    "def whiten1d():\n",
    "    # 1 D case\n",
    "    data = np.random.random(1000)\n",
    "    t1=time.time()\n",
    "    white_original = whiten_original(data, fft_para)\n",
    "    t2=time.time()\n",
    "    white_new = whiten(data, fft_para)\n",
    "    t3=time.time()\n",
    "    print(\"1D FFT took in scipy %f and in numpy %f\"%(t2-t1,t3-t2))\n",
    "\n",
    "    # A strict test does not work because the\n",
    "    assert np.sqrt(np.sum((white_original[0:500] - white_new[0:500]) ** 2) / 500.0) < 0.01 * white_new.max()\n",
    "    print(\"1D ok\")\n",
    "    return white_original, white_new\n",
    "\n",
    "\n",
    "def whiten2d():\n",
    "    # 2 D case\n",
    "    data = np.random.random((5, 1000))\n",
    "    t1=time.time()\n",
    "    white_original = whiten_original(data, fft_para)\n",
    "    t2=time.time()\n",
    "    white_new = whiten(data, fft_para)\n",
    "    t3=time.time()\n",
    "    print(\"2D FFT took in scipy %f and in numpy %f\"%(t2-t1,t3-t2))\n",
    "\n",
    "    for i in range(5):\n",
    "        assert (\n",
    "            np.sqrt(np.sum((white_original[i, 0:500] - white_new[i, 0:500]) ** 2) / 500.0)\n",
    "            < 0.01 * white_new[i, :].max()\n",
    "        )\n",
    "    print(\"2D ok\")\n",
    "    return white_original, white_new\n",
    "\n",
    "\n",
    "def plot_1d(white_original, white_new):\n",
    "    plt.plot(white_original[0:501].real)\n",
    "    plt.plot(white_new.real)\n",
    "    plt.show()\n",
    "    plt.plot(white_original[100:500].real - white_new[100:500].real)\n",
    "    plt.show()\n",
    "    plt.plot(white_original[100:500].imag - white_new[100:500].imag)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_2d(white_original, white_new):\n",
    "    for i in range(5):\n",
    "        plt.plot(white_original[i, :].real)\n",
    "        plt.plot(white_new[i, :].real)\n",
    "    plt.show()\n",
    "    for i in range(5):\n",
    "        plt.plot(white_original[i, 100:500].real - white_new[i, 100:500].real)\n",
    "    plt.show()\n",
    "    for i in range(5):\n",
    "        plt.plot(white_original[i, 100:500].imag - white_new[i, 100:500].imag)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_para['smoothspect_N']=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "white_original = whiten_original(data, fft_para)\n",
    "white_new = whiten(data, fft_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the fft vectors\n",
    "from scipy.fftpack import next_fast_len\n",
    "\n",
    "Nfft = int(next_fast_len(int(data.shape[0])))\n",
    "delta = 1 / d.sampling_rate\n",
    "freqVec = scipy.fftpack.fftfreq(Nfft, d=delta)[: Nfft // 2]\n",
    "freq_numpy= np.fft.fftfreq(Nfft, 1/d.sampling_rate)\n",
    "Napod = 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_para[\"smooth_N\"]=1000\n",
    "fft_para[\"freq_norm\"]=\"rma\"\n",
    "\n",
    "white_original = whiten_original(data, fft_para)\n",
    "white_new = whiten(data, fft_para)\n",
    "# fft_para = {\"dt\": 1/d.sampling_rate, \"freqmin\": config.freqmin, \"freqmax\": config.freqmax, \"smooth_N\": config.smoothspect_N, \"freq_norm\": config.freq_norm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(freq_numpy[:len(freq_numpy)//2],np.abs(white_new[:len(freq_numpy)//2]))\n",
    "plt.plot(freqVec,np.abs(white_original[:len(freqVec)]))\n",
    "plt.xscale(\"log\");plt.grid();#plt.yscale(\"log\") ;\n",
    "plt.xlim([0.001,11]);plt.ylim([0.01,2])\n",
    "print(freqVec[0:20],white_original[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redo the whitening itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.freqmax,config.freqmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(freq,np.abs(white_original))\n",
    "plt.plot(freq,np.abs(white_new))\n",
    "plt.plot(freq,np.abs(spec))\n",
    "plt.plot(freq,np.abs(white))\n",
    "plt.xlim([0.001,10]);plt.grid()\n",
    "plt.ylim([1e-5,1e9])\n",
    "plt.xscale(\"log\");plt.yscale(\"log\");\n",
    "plt.legend([\"Original from Noisepy.noise_module.whiten\",\"New from Carlos\",\"FFT\",\"NoiseP from noise_processing\"])\n",
    "plt.xlabel(\"Frequency [Hz]\");plt.ylabel(\"Amplitude\");\n",
    "plt.title(\"Whitening between %.1f and %1.1f \"%(config.freqmin,config.freqmax));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(white_original[100:500].real,white_new[100:500].real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# white_original, white_new = whiten2d()\n",
    "# plot_2d(white_original, white_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_processing(fft_para: ConfigParameters, dataS):\n",
    "    \"\"\"\n",
    "    this function performs time domain and frequency domain normalization if needed. in real case, we prefer use include\n",
    "    the normalization in the cross-correaltion steps by selecting coherency or decon\n",
    "    (Prieto et al, 2008, 2009; Denolle et al, 2013)\n",
    "    PARMAETERS:\n",
    "    ------------------------\n",
    "    fft_para: ConfigParameters class containing all useful variables used for fft and cc\n",
    "    dataS: 2D matrix of all segmented noise data\n",
    "    # OUTPUT VARIABLES:\n",
    "    source_white: 2D matrix of data spectra\n",
    "    \"\"\"\n",
    "    # ------to normalize in time or not------\n",
    "    if fft_para.time_norm != TimeNorm.NO:\n",
    "        if fft_para.time_norm == TimeNorm.ONE_BIT:  # sign normalization\n",
    "            white = np.sign(dataS)\n",
    "        elif fft_para.time_norm == TimeNorm.RMA:  # running mean: normalization over smoothed absolute average\n",
    "            white = np.zeros(shape=dataS.shape, dtype=dataS.dtype)\n",
    "            for kkk in range(dataS.shape[0]):\n",
    "                white[kkk, :] = dataS[kkk, :] / moving_ave(np.abs(dataS[kkk, :]), fft_para.smooth_N)\n",
    "\n",
    "    else:  # don't normalize\n",
    "        white = dataS\n",
    "\n",
    "    # -----to whiten or not------\n",
    "    if fft_para.freq_norm != FreqNorm.NO:\n",
    "        source_white = whiten(white, fft_para)  # whiten and return FFT\n",
    "    else:\n",
    "        Nfft = int(next_fast_len(int(dataS.shape[1])))\n",
    "        source_white = scipy.fftpack.fft(white, Nfft, axis=1)  # return FFT\n",
    "\n",
    "    return source_white"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQ-ey7uX9Msx"
   },
   "source": [
    "Plot a single set of the cross correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWcrfWO8W1tH"
   },
   "outputs": [],
   "source": [
    "timespans = cc_store.get_timespans()\n",
    "plotting_modules.plot_substack_cc(cc_store, timespans[0], 0.1, 1, 200, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMeH9BslQSSJ"
   },
   "source": [
    "## Step 3: Stack the cross correlation\n",
    "\n",
    "Provide a path to where the data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd32ntmAVx-z"
   },
   "outputs": [],
   "source": [
    "# open a new cc store in read-only mode since we will be doing parallel access for stacking\n",
    "cc_store = ASDFCCStore(cc_data_path, mode=\"r\")\n",
    "stack_store = ASDFStackStore(stack_data_path)\n",
    "stack(cc_store, stack_store, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Of_MzZWFQ_Yn"
   },
   "source": [
    "Plot the stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3YC3JX5lSKu"
   },
   "outputs": [],
   "source": [
    "print(os.listdir(cc_data_path))\n",
    "print(os.listdir(stack_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKSeQpk7WKlW"
   },
   "outputs": [],
   "source": [
    "plotting_modules.plot_all_moveout(stack_store, 'Allstack_linear', 0.1, 0.2, 'ZZ', 1)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
