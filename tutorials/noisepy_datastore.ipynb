{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIA2IaqUOeOA"
   },
   "source": [
    "# NoisePy DataStore Tutorial\n",
    "Introduction to the NoisePy DataStore class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this line if the environment doesn't have noisepy already installed:\n",
    "# ! pip install noisepy-seis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Warning__: NoisePy uses ```obspy``` as a core Python module to manipulate seismic data. Restart the runtime now for proper installation of ```obspy``` on Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaKuajVCOo2r"
   },
   "source": [
    "This tutorial should be ran after installing the noisepy package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vceZgD83PnNc"
   },
   "outputs": [],
   "source": [
    "from noisepy.seis import  __version__       # noisepy core functions\n",
    "from noisepy.seis.io.s3store import SCEDCS3DataStore # Object to query SCEDC data from on S3\n",
    "from noisepy.seis.io.channel_filter_store import channel_filter\n",
    "from noisepy.seis.io.channelcatalog import XMLStationChannelCatalog        # Required stationXML handling object\n",
    "from datetime import datetime\n",
    "from datetimerange import DateTimeRange\n",
    "\n",
    "print(f\"Using NoisePy version {__version__}\")\n",
    "\n",
    "S3_STORAGE_OPTIONS = {\"s3\": {\"anon\": True}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yojR0Z3ALm6K"
   },
   "outputs": [],
   "source": [
    "# timeframe for analysis\n",
    "start = datetime(2022, 1, 2)\n",
    "end = datetime(2022, 1, 4)\n",
    "time_range = DateTimeRange(start, end)\n",
    "print(time_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A noisepy DataStore is a set of classes to accommodate the various types of data store that are necessary because how reseachers store their data, which can be dramatically different w.r.t. formats (mSEED, SAC, SEG-Y), file system (local, S3), and naming conventions. Our noisepy team does not impose a definite data structure, but instead suggest to wrap the data storage structure into a python class. A Data Store class can be the front-end of the real back-end data storage, and return data through read_data function. It allows users to customize based on how they store the data, and leaving the rest of the workflow untouched.\n",
    "\n",
    "See https://github.com/noisepy/noisepy-io/blob/main/src/noisepy/seis/stores.py for more about `DataStore` Class.\n",
    "\n",
    "### S3 DataStore\n",
    "Here, we instantiate a `SCEDCS3DataStore` class as `raw_store` as an example of Data Store on the cloud. This variable allows reading data from the real data storage backend during the later processing. The initialization parameters of `SCEDCS3DataStore` are\n",
    "- S3_DATA: path to the data in the `\"s3://\"` format. \n",
    "- catalog: path to the station XML available in the `\"s3://\"` format.\n",
    "- channel_filter: channel selection, based on station name and/or channel type.\n",
    "- time_range: DateTimeRange of data for processing.\n",
    "- storage_option: optimal storage option to read S3 data. This is where you can put AWS keys/credential if applicable.\n",
    "\n",
    "See https://github.com/noisepy/noisepy-io/blob/main/src/noisepy/seis/io/s3store.py for `SCEDCS3DataStore`\n",
    "\n",
    "We will work with a single day worth of data on SCEDC. The continuous data is organized with a single day and channel per miniseed (https://scedc.caltech.edu/data/cloud.html). For this example, you can choose any year since 2002. We will just cross correlate a single day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jq2DKIS9Rl2H"
   },
   "outputs": [],
   "source": [
    "# SCEDC S3 bucket common URL characters for that day.\n",
    "S3_DATA = \"s3://scedc-pds/continuous_waveforms/\"\n",
    "\n",
    "# S3 storage of stationXML\n",
    "S3_STATION_XML = \"s3://scedc-pds/FDSNstationXML/CI/\"  \n",
    "\n",
    "stations = \"SBC,RIO,DEV\".split(\",\") # filter to these stations\n",
    "catalog = XMLStationChannelCatalog(S3_STATION_XML, storage_options=S3_STORAGE_OPTIONS) # Station catalog\n",
    "raw_store = SCEDCS3DataStore(S3_DATA, catalog, \n",
    "                             channel_filter([\"CI\"], stations, [\"BHE\", \"BHN\", \"BHZ\",\n",
    "                                                               \"EHE\", \"EHN\", \"EHZ\"]), \n",
    "                             time_range, \n",
    "                             storage_options=S3_STORAGE_OPTIONS) # Store for reading raw data from S3 bucket\n",
    "raw_store.fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know what method was defined under the DataStore, we can list them as follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_list = [method for method in dir(raw_store) if method.startswith('__') is False]\n",
    "print(method_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `get_timespan` function cuts the whole time span into each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span = raw_store.get_timespans()\n",
    "print(span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get metadata of available channels\n",
    "\n",
    "The `get_channel` function takes a time span, and read all stationXML for that specific day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = raw_store.get_channels(span[0])\n",
    "channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data\n",
    "With the time and channel list, we can use `read_data` function to read the data. Note that the returned channel data is parsed into NoisePy `ChannelData` type. \n",
    "\n",
    "The data type ``stream`` is a typical obspy stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = raw_store.read_data(span[0], channels[2])\n",
    "d.stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.stream.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
