{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIA2IaqUOeOA"
   },
   "source": [
    "# Getting Started\n",
    "\n",
    "Welcome to the NoisePy Colab Tutorial!\n",
    "\n",
    "This tutorial will walk you through the basic steps of using NoisePy to compute ambient noise cross correlation functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaKuajVCOo2r"
   },
   "source": [
    "First, we install the noisepy-seis package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rR860zaZPZGH"
   },
   "outputs": [],
   "source": [
    "# Uncomment and run this line if the environment doesn't have noisepy already installed:\n",
    "# ! pip install noisepy-seis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QvfrDdZOv12"
   },
   "source": [
    "__Warning__: NoisePy uses ```obspy``` as a core Python module to manipulate seismic data. Restart the runtime now for proper installation of ```obspy``` on Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtDb2_y3Oreg"
   },
   "source": [
    "Then we import the basic modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vceZgD83PnNc"
   },
   "outputs": [],
   "source": [
    "from noisepy.seis import download, cross_correlate, stack_cross_correlations, plotting_modules, __version__\n",
    "from noisepy.seis.asdfstore import ASDFRawDataStore, ASDFCCStore, ASDFStackStore\n",
    "from noisepy.seis.datatypes import CCMethod, ConfigParameters, FreqNorm, RmResp, TimeNorm\n",
    "from dateutil.parser import isoparse\n",
    "import os\n",
    "import shutil\n",
    "print(f\"Using NoisePy version {__version__}\")\n",
    "\n",
    "path = os.path.join(\".\", \"get_started_data\")\n",
    "\n",
    "os.makedirs(path,exist_ok=True)\n",
    "raw_data_path = os.path.join(path, \"RAW_DATA\")\n",
    "cc_data_path = os.path.join(path, \"CCF\")\n",
    "stack_data_path = os.path.join(path, \"STACK\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambient Noise Project Configuration\n",
    "\n",
    "We store the metadata information about the ambient noise cross correlation workflow in a ConfigParameters() object. We first initialize it, then we tune the parameters for this cross correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigParameters() # default config parameters which can be customized\n",
    "config.inc_hours = 12\n",
    "config.samp_freq= 20  # (int) Sampling rate in Hz of desired processing (it can be different than the data sampling rate)\n",
    "config.cc_len= 3600  # (float) basic unit of data length for fft (sec)\n",
    "    # criteria for data selection\n",
    "config.ncomp = 3  # 1 or 3 component data (needed to decide whether do rotation)\n",
    "\n",
    "\n",
    "config.acorr_only = False  # only perform auto-correlation or not\n",
    "config.xcorr_only = True  # only perform cross-correlation or not\n",
    "\n",
    "config.inc_hours = 12 # if the data is first \n",
    "\n",
    "config.lamin = 31       # min latitude\n",
    "config.lamax = 42       # max latitude\n",
    "config.lomin = -124     # min longitude\n",
    "config.lomax = -115     # max longitude\n",
    "config.net_list = [\"*\"] # look for all network codes\n",
    "\n",
    "\n",
    "\n",
    " # pre-processing parameters\n",
    "config.step= 1800.0  # (float) overlapping between each cc_len (sec)\n",
    "config.stationxml= False  # station.XML file used to remove instrument response for SAC/miniseed data\n",
    "config.rm_resp= RmResp.INV  # select 'no' to not remove response and use 'inv' if you use the stationXML,'spectrum',\n",
    "config.freqmin = 0.05\n",
    "config.freqmax = 2.0\n",
    "config.max_over_std  = 10  # threshold to remove window of bad signals: set it to 10*9 if prefer not to remove them\n",
    "\n",
    "# TEMPORAL and SPECTRAL NORMALISATION\n",
    "config.freq_norm= FreqNorm.RMA # choose between \"rma\" for a soft whitenning or \"no\" for no whitening. Pure whitening is not implemented correctly at this point.\n",
    "config.smoothspect_N = 10  # moving window length to smooth spectrum amplitude (points)\n",
    "    # here, choose smoothspect_N for the case of a strict whitening (e.g., phase_only)\n",
    "\n",
    "config.time_norm = TimeNorm.NO  # 'no' for no normalization, or 'rma', 'one_bit' for normalization in time domain,\n",
    "    # TODO: change time_norm option from \"no\" to \"None\"\n",
    "config.smooth_N= 10  # moving window length for time domain normalization if selected (points)\n",
    "\n",
    "config.cc_method= CCMethod.XCORR # 'xcorr' for pure cross correlation OR 'deconv' for deconvolution;\n",
    "    # FOR \"COHERENCY\" PLEASE set freq_norm to \"rma\", time_norm to \"no\" and cc_method to \"xcorr\"\n",
    "\n",
    "# OUTPUTS:\n",
    "config.substack = True  # True = smaller stacks within the time chunk. False: it will stack over inc_hours\n",
    "config.substack_len = config.cc_len  # how long to stack over (for monitoring purpose): need to be multiples of cc_len\n",
    "    # if substack=True, substack_len=2*cc_len, then you pre-stack every 2 correlation windows.\n",
    "    # for instance: substack=True, substack_len=cc_len means that you keep ALL of the correlations\n",
    "\n",
    "config.maxlag= 200  # lags of cross-correlation to save (sec)\n",
    "config.substack = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "c5JaBXKpO_Oi"
   },
   "source": [
    "## Step 0: download data\n",
    "\n",
    "\n",
    "This step will download data using obspy and save them into ASDF files locally. The data will be stored for each time chunk defined in hours by inc_hours.\n",
    "\n",
    "The download will clean up the raw data by detrending, removing the mean, bandpassing (broadly), removing the instrumental response, merging gaps, ignoring too-gappy data.\n",
    "\n",
    "Use the function ```download``` with the following arguments: \n",
    "* ```path```:where to put the data\n",
    "* ```config```: configuration settings, in particular:\n",
    "    * ```channel```: list of the seismic channels to download, and example is shown below\n",
    "    * ```stations```: list of the seismic stations, it can be \"\\*\" (not \"all\") \n",
    "    * ```start_time```\n",
    "    * ```end_time```\n",
    "* ```client_url_key```: the string for FDSN clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwJNnRURPxfW"
   },
   "outputs": [],
   "source": [
    "config.stations = [\"A*\"]\n",
    "config.channels =  [\"BHE\",\"BHN\",\"BHZ\"]\n",
    "config.start_date =  isoparse(\"2019-02-01T00:00:00Z\")\n",
    "config.end_date = isoparse(\"2019-02-02T00:00:00Z\")\n",
    "\n",
    "# Download data locally. Enters raw data path, channel types, stations, config, and fdsn server.\n",
    "download(raw_data_path, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the files that were downloaded, just to make sure !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klpx413Ty8zK"
   },
   "outputs": [],
   "source": [
    "print(os.listdir(raw_data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the raw data, make sure it's noise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "To29cLijWzdQ"
   },
   "outputs": [],
   "source": [
    "file = os.path.join(raw_data_path, \"2019_02_01_00_00_00T2019_02_01_12_00_00.h5\")\n",
    "raw_store = ASDFRawDataStore(raw_data_path) # Store for reading raw data\n",
    "timespans = raw_store.get_timespans()\n",
    "plotting_modules.plot_waveform(raw_store, timespans[0], 'CI','ADO',0.01,0.4) # this function takes for input: filename, network, station, freqmin, freqmax for a bandpass filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wwv1QCQhP_0Y"
   },
   "source": [
    "## Step 1: Cross-correlation\n",
    "\n",
    "This step will perform the cross correlation. For each time chunk, it will read the data, perform classic ambient noise pre-processing (time and frequency normalization), FFT, cross correlation, substacking, saving cross correlations in to a temp ASDF file (this is not fast and will be improved).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this tutorial make sure the previous run is empty\n",
    "if os.path.exists(cc_data_path):\n",
    "    shutil.rmtree(cc_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jq2DKIS9Rl2H"
   },
   "outputs": [],
   "source": [
    "config.freq_norm = FreqNorm.RMA\n",
    "cc_store = ASDFCCStore(cc_data_path) # Store for writing CC data\n",
    "\n",
    "# print the configuration parameters. Some are chosen by default but we cab modify them\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the cross correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_correlate(raw_store, config, cc_store)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a single set of the cross correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWcrfWO8W1tH"
   },
   "outputs": [],
   "source": [
    "pairs = cc_store.get_station_pairs()\n",
    "timespans = cc_store.get_timespans(*pairs[0])\n",
    "plotting_modules.plot_substack_cc(cc_store, timespans[0], 0.1, 1, 200, False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GMeH9BslQSSJ"
   },
   "source": [
    "## Step 2: Stack the cross correlation\n",
    "\n",
    "This combines the time-chunked ASDF files to stack over each time chunk and at each station pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd32ntmAVx-z"
   },
   "outputs": [],
   "source": [
    "# open a new cc store in read-only mode since we will be doing parallel access for stacking\n",
    "cc_store = ASDFCCStore(cc_data_path, mode=\"r\")\n",
    "print(cc_store.get_station_pairs())\n",
    "stack_store = ASDFStackStore(stack_data_path)\n",
    "config.stations = [\"*\"] # stacking doesn't support prefixes yet, so allow all stations\n",
    "stack_cross_correlations(cc_store, stack_store, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = stack_store.get_station_pairs()\n",
    "print(f\"Found {len(pairs)} station pairs\")\n",
    "sta_stacks = stack_store.read_bulk(None, pairs) # no timestamp used in ASDFStackStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Of_MzZWFQ_Yn"
   },
   "source": [
    "Plot the stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3YC3JX5lSKu"
   },
   "outputs": [],
   "source": [
    "print(os.listdir(cc_data_path))\n",
    "print(os.listdir(stack_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKSeQpk7WKlW"
   },
   "outputs": [],
   "source": [
    "plotting_modules.plot_all_moveout(sta_stacks, 'Allstack_linear', 0.1, 0.2, 'ZZ', 1)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
