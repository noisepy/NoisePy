{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIA2IaqUOeOA"
      },
      "source": [
        "# Welcome to the NoisePy SCEDC Colab Tutorial!\n",
        "\n",
        "Noisepy is a python software package to process ambient seismic noise cross correlations. \n",
        "\n",
        "**Publication about this software**:\n",
        "Chengxin Jiang, Marine A. Denolle; NoisePy: A New High‐Performance Python Tool for Ambient‐Noise Seismology. Seismological Research Letters 2020; 91 (3): 1853–1866. doi: https://doi.org/10.1785/0220190364\n",
        "\n",
        "\n",
        "\n",
        "This tutorial will walk you through the basic steps of using NoisePy to compute ambient noise cross correlation functions using single instance workflow.\n",
        "\n",
        "The data is stored on AWS S3 as the SCEDC Data Set: https://scedc.caltech.edu/data/getstarted-pds.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaKuajVCOo2r"
      },
      "source": [
        "First, we install the noisepy-seis package. ```NoisePy``` includes ```obspy``` as a depedency, therefore it is required to **restart runtime** after installation of noisepy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR860zaZPZGH"
      },
      "outputs": [],
      "source": [
        "\n",
        "! pip install --upgrade noisepy-seis\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QvfrDdZOv12"
      },
      "source": [
        "## Restart runtime\n",
        "\n",
        "Required to properly install obspy on Colab instances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtDb2_y3Oreg"
      },
      "source": [
        "## Import necessary modules\n",
        "\n",
        "Then we import the basic modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vceZgD83PnNc"
      },
      "outputs": [],
      "source": [
        "from noisepy.seis import cross_correlate, stack, plotting_modules       # noisepy core functions\n",
        "from noisepy.seis.asdfstore import ASDFCCStore                          # Object to store ASDF data within noisepy\n",
        "from noisepy.seis.scedc_s3store import SCEDCS3DataStore, channel_filter # Object to query SCEDC data from on S3\n",
        "from noisepy.seis.datatypes import ConfigParameters                     # Main configuration object\n",
        "from noisepy.seis.channelcatalog import XMLStationChannelCatalog        # Required stationXML handling object\n",
        "import os\n",
        "import glob\n",
        "\n",
        "\n",
        "# create directory to store data locally\n",
        "path = \"./data\"\n",
        "# path = \"../../data/\" # for local runs\n",
        "os.makedirs(path, exist_ok=True)\n",
        "cc_data_path = os.path.join(path, \"CCF\")\n",
        "stack_data_path = os.path.join(path, \"STACK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pntYzIYGNTn8"
      },
      "source": [
        "We will work with a single day worth of data on SCEDC. The continuous data is organized with a single day and channel per miniseed (https://scedc.caltech.edu/data/cloud.html). For this example, you can choose any year since 2002. We will just cross correlate a single day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yojR0Z3ALm6K"
      },
      "outputs": [],
      "source": [
        "year = 2002     # year of analysis\n",
        "doy = 2         # day of year (1-365)\n",
        "# SCEDC S3 bucket common URL characters for that day.\n",
        "S3_DATA = \"s3://scedc-pds/continuous_waveforms/\"+str(year)+\"/\"+str(year)+\"_\"+str(doy).zfill(3)+\"/\"  # 1 day of data\n",
        "print(S3_DATA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1CC-BljNzus"
      },
      "source": [
        "The station information, including the instrumental response, is stored as stationXML in the following bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhfgrMPALsYS"
      },
      "outputs": [],
      "source": [
        "S3_STATION_XML = \"s3://scedc-pds/FDSNstationXML/CI/\"            # S3 storage of stationXML\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssaL5fa5IhI7"
      },
      "source": [
        "## Ambient Noise Project Configuration\n",
        "\n",
        "We store the metadata information about the ambient noise cross correlation workflow in a ConfigParameters() object. We first initialize it, then we tune the parameters for this cross correlation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIjBD7riIfdJ"
      },
      "outputs": [],
      "source": [
        "# Initialize ambient noise workflow configuration\n",
        "config = ConfigParameters() # default config parameters which can be customized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tsp7RfC8IwE-"
      },
      "source": [
        "Customize the job parameters below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByEiHRjmIAPB"
      },
      "outputs": [],
      "source": [
        "config.dt= 0.05  # float: dt is constrained to be 1/sampling rate\n",
        "# config.start_date: str(year)+\"_\"  # TODO: can we make this datetime?\n",
        "# config.end_date: str = \"\"\n",
        "config.samp_freq= 20  # (int) Sampling rate in Hz of desired processing (it can be different than the data sampling rate)\n",
        "config.cc_len= 3600.0  # (float) basic unit of data length for fft (sec)\n",
        "    # criteria for data selection\n",
        "config.ncomp = 3  # 1 or 3 component data (needed to decide whether do rotation)\n",
        "\n",
        "\n",
        "config.acorr_only = False  # only perform auto-correlation or not\n",
        "config.xcorr_only = True  # only perform cross-correlation or not\n",
        "\n",
        "# config.inc_hours = 24 # if the data is first \n",
        "\n",
        " # pre-processing parameters\n",
        "config.step= 1800.0  # (float) overlapping between each cc_len (sec)\n",
        "config.stationxml= False  # station.XML file used to remove instrument response for SAC/miniseed data\n",
        "config.rm_resp= \"inv\"  # select 'no' to not remove response and use 'inv' if you use the stationXML,'spectrum',\n",
        "config.freqmin = 0.05\n",
        "config.freqmax = 2.0\n",
        "config.max_over_std  = 10  # threshold to remove window of bad signals: set it to 10*9 if prefer not to remove them\n",
        "\n",
        "# TEMPORAL and SPECTRAL NORMALISATION\n",
        "config.freq_norm= \"rma\"  # choose between \"rma\" for a soft whitenning or \"no\" for no whitening. Pure whitening is not implemented correctly at this point.\n",
        "config.smoothspect_N = 10  # moving window length to smooth spectrum amplitude (points)\n",
        "    # here, choose smoothspect_N for the case of a strict whitening (e.g., phase_only)\n",
        "\n",
        "config.time_norm = \"no\"  # 'no' for no normalization, or 'rma', 'one_bit' for normalization in time domain,\n",
        "    # TODO: change time_norm option from \"no\" to \"None\"\n",
        "config.smooth_N= 10  # moving window length for time domain normalization if selected (points)\n",
        "\n",
        "config.cc_method= \"xcorr\"  # 'xcorr' for pure cross correlation OR 'deconv' for deconvolution;\n",
        "    # FOR \"COHERENCY\" PLEASE set freq_norm to \"rma\", time_norm to \"no\" and cc_method to \"xcorr\"\n",
        "\n",
        "# OUTPUTS:\n",
        "config.substack = True  # True = smaller stacks within the time chunk. False: it will stack over inc_hours\n",
        "config.substack_len = config.cc_len  # how long to stack over (for monitoring purpose): need to be multiples of cc_len\n",
        "    # if substack=True, substack_len=2*cc_len, then you pre-stack every 2 correlation windows.\n",
        "    # for instance: substack=True, substack_len=cc_len means that you keep ALL of the correlations\n",
        "\n",
        "config.maxlag= 200  # lags of cross-correlation to save (sec)\n",
        "config.substack = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For this tutorial make sure the previous run is empty\n",
        "!rm -rf ./data/CCF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wwv1QCQhP_0Y"
      },
      "source": [
        "## Step 1: Cross-correlation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq2DKIS9Rl2H"
      },
      "outputs": [],
      "source": [
        "\n",
        "stations = \"SBC,RIO,DEV\".split(\",\") # filter to these stations\n",
        "catalog = XMLStationChannelCatalog(S3_STATION_XML)\n",
        "raw_store = SCEDCS3DataStore(S3_DATA, catalog, channel_filter(stations, \"BH\")) # Store for reading raw data from S3 bucket\n",
        "cc_store = ASDFCCStore(cc_data_path) # Store for writing CC data\n",
        "\n",
        "# print the configuration parameters. Some are chosen by default but we can modify them\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4eIzDJtkWks"
      },
      "outputs": [],
      "source": [
        "ts = raw_store.get_timespans()\n",
        "raw_store.get_channels(ts[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qsPGkNp9Msx"
      },
      "source": [
        "Perform the cross correlation\n",
        "Here, removing the instrumental response is slow. It could also be the interpolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49MnDXYp9Msx"
      },
      "outputs": [],
      "source": [
        "cross_correlate(raw_store, config, cc_store)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ-ey7uX9Msx"
      },
      "source": [
        "Plot a single set of the cross correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWcrfWO8W1tH"
      },
      "outputs": [],
      "source": [
        "file = os.path.join(cc_data_path, '2002_01_02_00_00_00T2002_01_03_00_00_00.h5')\n",
        "plotting_modules.plot_substack_cc(file,0.1,1,200,False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMeH9BslQSSJ"
      },
      "source": [
        "## Step 3: Stack the cross correlation\n",
        "\n",
        "STILL NEEDS TO BE FIXED\n",
        "\n",
        "Provide a path to where the data is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd32ntmAVx-z"
      },
      "outputs": [],
      "source": [
        "stations = raw_store.get_station_list()\n",
        "print(stations)\n",
        "stack(stations, cc_data_path, stack_data_path, \"linear\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of_MzZWFQ_Yn"
      },
      "source": [
        "Plot the stacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3YC3JX5lSKu"
      },
      "outputs": [],
      "source": [
        "print(os.listdir(cc_data_path))\n",
        "print(os.listdir(stack_data_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKSeQpk7WKlW"
      },
      "outputs": [],
      "source": [
        "files = glob.glob(os.path.join(stack_data_path, '**/*.h5'))\n",
        "print(files)\n",
        "plotting_modules.plot_all_moveout(files, 'Allstack_linear', 0.1, 0.2, 'ZZ', 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caaU2Hr39Msy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "@webio": {
      "lastCommId": null,
      "lastKernelId": null
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
