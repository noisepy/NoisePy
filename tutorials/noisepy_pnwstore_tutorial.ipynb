{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIA2IaqUOeOA"
   },
   "source": [
    "# Welcome to the NoisePy SCEDC Tutorial!\n",
    "\n",
    "Noisepy is a python software package to process ambient seismic noise cross correlations. \n",
    "\n",
    "**Publication about this software**:\n",
    "Chengxin Jiang, Marine A. Denolle; NoisePy: A New High‐Performance Python Tool for Ambient‐Noise Seismology. Seismological Research Letters 2020; 91 (3): 1853–1866. doi: https://doi.org/10.1785/0220190364\n",
    "\n",
    "\n",
    "\n",
    "This tutorial will walk you through the basic steps of using NoisePy to compute ambient noise cross correlation functions using single instance workflow.\n",
    "\n",
    "The data is stored on AWS S3 as the SCEDC Data Set: https://scedc.caltech.edu/data/getstarted-pds.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we install the noisepy-seis package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this line if the environment doesn't have noisepy already installed:\n",
    "# ! pip install noisepy-seis[sql] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Warning__: NoisePy uses ```obspy``` as a core Python module to manipulate seismic data. Restart the runtime now for proper installation of ```obspy``` on Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaKuajVCOo2r"
   },
   "source": [
    "This tutorial should be ran after installing the noisepy package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtDb2_y3Oreg"
   },
   "source": [
    "## Import necessary modules\n",
    "\n",
    "Then we import the basic modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vceZgD83PnNc"
   },
   "outputs": [],
   "source": [
    "from noisepy.seis import cross_correlate, stack_cross_correlations, plotting_modules       # noisepy core functions\n",
    "from noisepy.seis.asdfstore import ASDFCCStore, ASDFStackStore                          # Object to store ASDF data within noisepy\n",
    "from noisepy.seis.scedc_s3store import channel_filter\n",
    "from noisepy.seis.pnwstore import PNWDataStore\n",
    "from noisepy.seis.datatypes import CCMethod, ConfigParameters, Channel, ChannelData, ChannelType, FreqNorm, Station, TimeNorm    # Main configuration object\n",
    "from noisepy.seis.channelcatalog import XMLStationChannelCatalog        # Required stationXML handling object\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetimerange import DateTimeRange\n",
    "\n",
    "\n",
    "path = \"./pnw_data\" \n",
    "\n",
    "os.makedirs(path, exist_ok=True)\n",
    "cc_data_path = os.path.join(path, \"CCF\")\n",
    "stack_data_path = os.path.join(path, \"STACK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATION_XML = \"/1-fnp/pnwstore1/p-wd11/PNWStationXML/\"            # storage of stationXML\n",
    "DATA = \"/1-fnp/pnwstore1/p-wd00/PNW2020/__/\"                      # __ indicates any two chars (network code)\n",
    "DB_PATH=\"/1-fnp/pnwstore1/p-wd00/PNW2020/timeseries.sqlite\"\n",
    "# timeframe for analysis\n",
    "start = datetime(2020, 1, 2)\n",
    "end = datetime(2020, 1, 4)\n",
    "range = DateTimeRange(start, end)\n",
    "print(range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pntYzIYGNTn8"
   },
   "source": [
    "We will work with a single day worth of data on SCEDC. The continuous data is organized with a single day and channel per miniseed (https://scedc.caltech.edu/data/cloud.html). For this example, you can choose any year since 2002. We will just cross correlate a single day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1CC-BljNzus"
   },
   "source": [
    "The station information, including the instrumental response, is stored as stationXML in the following bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssaL5fa5IhI7"
   },
   "source": [
    "## Ambient Noise Project Configuration\n",
    "\n",
    "We store the metadata information about the ambient noise cross correlation workflow in a ConfigParameters() object. We first initialize it, then we tune the parameters for this cross correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIjBD7riIfdJ"
   },
   "outputs": [],
   "source": [
    "# Initialize ambient noise workflow configuration\n",
    "config = ConfigParameters() # default config parameters which can be customized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tsp7RfC8IwE-"
   },
   "source": [
    "Customize the job parameters below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ByEiHRjmIAPB"
   },
   "outputs": [],
   "source": [
    "config.samp_freq= 20  # (int) Sampling rate in Hz of desired processing (it can be different than the data sampling rate)\n",
    "config.cc_len= 3600  # (float) basic unit of data length for fft (sec)\n",
    "    # criteria for data selection\n",
    "config.ncomp = 3  # 1 or 3 component data (needed to decide whether do rotation)\n",
    "\n",
    "\n",
    "config.acorr_only = False  # only perform auto-correlation or not\n",
    "config.xcorr_only = True  # only perform cross-correlation or not\n",
    "\n",
    "# config.inc_hours = 24 # if the data is first \n",
    "\n",
    " # pre-processing parameters\n",
    "config.step= 1800.0  # (float) overlapping between each cc_len (sec)\n",
    "config.stationxml= False  # station.XML file used to remove instrument response for SAC/miniseed data\n",
    "config.rm_resp= \"inv\"  # select 'no' to not remove response and use 'inv' if you use the stationXML,'spectrum',\n",
    "config.freqmin = 0.05\n",
    "config.freqmax = 2.0\n",
    "config.max_over_std  = 10  # threshold to remove window of bad signals: set it to 10*9 if prefer not to remove them\n",
    "\n",
    "# TEMPORAL and SPECTRAL NORMALISATION\n",
    "config.freq_norm= FreqNorm.RMA  # choose between \"rma\" for a soft whitenning or \"no\" for no whitening. Pure whitening is not implemented correctly at this point.\n",
    "config.smoothspect_N = 10  # moving window length to smooth spectrum amplitude (points)\n",
    "    # here, choose smoothspect_N for the case of a strict whitening (e.g., phase_only)\n",
    "\n",
    "config.time_norm = TimeNorm.NO  # 'no' for no normalization, or 'rma', 'one_bit' for normalization in time domain,\n",
    "    # TODO: change time_norm option from \"no\" to \"None\"\n",
    "config.smooth_N= 10  # moving window length for time domain normalization if selected (points)\n",
    "\n",
    "config.cc_method= CCMethod.XCORR  # 'xcorr' for pure cross correlation OR 'deconv' for deconvolution;\n",
    "    # FOR \"COHERENCY\" PLEASE set freq_norm to \"rma\", time_norm to \"no\" and cc_method to \"xcorr\"\n",
    "\n",
    "# OUTPUTS:\n",
    "config.substack = True  # True = smaller stacks within the time chunk. False: it will stack over inc_hours\n",
    "config.substack_len = config.cc_len  # how long to stack over (for monitoring purpose): need to be multiples of cc_len\n",
    "    # if substack=True, substack_len=2*cc_len, then you pre-stack every 2 correlation windows.\n",
    "    # for instance: substack=True, substack_len=cc_len means that you keep ALL of the correlations\n",
    "\n",
    "config.maxlag= 200  # lags of cross-correlation to save (sec)\n",
    "config.substack = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this tutorial make sure the previous run is empty\n",
    "os.system(f\"rm -rf {cc_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wwv1QCQhP_0Y"
   },
   "source": [
    "## Step 1: Cross-correlation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross network, cross channel type\n",
    "# UW.BBO..HH\n",
    "# UW.BABR..HH\n",
    "# UW.SHUK..BH\n",
    "# CC.PANH..BH\n",
    "stations = \"BBO,BABR,SHUK,PANH\".split(\",\") # filter to these stations\n",
    "catalog = XMLStationChannelCatalog(STATION_XML, path_format=\"{network}\" + os.path.sep + \"{network}.{name}.xml\")\n",
    "raw_store = PNWDataStore(DATA, catalog, DB_PATH, channel_filter(stations, \"BH,HH\"), date_range=range) # Store for reading raw data from S3 bucket\n",
    "cc_store = ASDFCCStore(cc_data_path) # Store for writing CC data\n",
    "# print the configuration parameters. Some are chosen by default but we can modify them\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qsPGkNp9Msx"
   },
   "source": [
    "Perform the cross correlation\n",
    "Here, removing the instrumental response is slow. It could also be the interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49MnDXYp9Msx"
   },
   "outputs": [],
   "source": [
    "cross_correlate(raw_store, config, cc_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQ-ey7uX9Msx"
   },
   "source": [
    "Plot a single set of the cross correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWcrfWO8W1tH",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timespans = cc_store.get_timespans()\n",
    "plotting_modules.plot_substack_cc(cc_store, timespans[0], 0.1, 1, None, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMeH9BslQSSJ"
   },
   "source": [
    "## Step 3: Stack the cross correlation\n",
    "\n",
    "STILL NEEDS TO BE FIXED\n",
    "\n",
    "Provide a path to where the data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd32ntmAVx-z"
   },
   "outputs": [],
   "source": [
    "# open a new cc store in read-only mode since we will be doing parallel access for stacking\n",
    "cc_store = ASDFCCStore(cc_data_path, mode=\"r\")\n",
    "stack_store = ASDFStackStore(stack_data_path)\n",
    "stack_cross_correlations(cc_store, stack_store, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Of_MzZWFQ_Yn"
   },
   "source": [
    "Plot the stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3YC3JX5lSKu"
   },
   "outputs": [],
   "source": [
    "print(os.listdir(cc_data_path))\n",
    "print(os.listdir(stack_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = stack_store.get_station_pairs()\n",
    "print(f\"Found {len(pairs)} station pairs\")\n",
    "sta_stacks = stack_store.read_bulk(None, pairs) # no timestamp used in ASDFStackStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKSeQpk7WKlW"
   },
   "outputs": [],
   "source": [
    "plotting_modules.plot_all_moveout(sta_stacks, 'Allstack_linear', 0.1, 0.2, 'ZZ', 1)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
