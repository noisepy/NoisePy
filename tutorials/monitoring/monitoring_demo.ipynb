{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIA2IaqUOeOA"
   },
   "source": [
    "# Welcome to the NoisePy Post-processing Tutorial\n",
    "\n",
    "This tutorial will demonstrate how to use NoisePy's output to perform monitoring on correlations: measuring of changes in seismic velocities and intrinsic atteunation parameters (for single-station measurement).\n",
    "- Step 0. Import used modules and setup the config parameters of the noisepy output\n",
    "- Step 1. Cross correlate\n",
    "- Step 2. Read data from the NoisePy CCstore \n",
    "- Step 3. Look at invidual traces and make dv/v measurements\n",
    "- Step 4. Measure dv/v on all cross-components\n",
    "- Step 5. Measure attenuation parameter: intrinsic absorption parameter b\n",
    "- Step 6. Output results as a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtDb2_y3Oreg"
   },
   "source": [
    "### Step 0 - Import modules and setup config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4304,
     "status": "ok",
     "timestamp": 1687293359985,
     "user": {
      "displayName": "Kuan-Fu Feng",
      "userId": "10709727719882205429"
     },
     "user_tz": 420
    },
    "id": "vceZgD83PnNc",
    "outputId": "814f511d-96bb-4794-f949-10ac7d1f19b5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os, logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from obspy.signal.filter import bandpass\n",
    "from datetime import datetime, timezone\n",
    "from datetimerange import DateTimeRange\n",
    "\n",
    "from noisepy.seis import noise_module, cross_correlate\n",
    "from noisepy.seis.io.asdfstore import ASDFCCStore\n",
    "from noisepy.seis.io.datatypes import ConfigParameters, StackMethod, CCMethod, FreqNorm, RmResp, TimeNorm \n",
    "from noisepy.seis.io.channel_filter_store import channel_filter\n",
    "from noisepy.seis.io.channelcatalog import XMLStationChannelCatalog        # Required stationXML handling object\n",
    "from noisepy.seis.io.s3store import SCEDCS3DataStore    # Object to query SCEDC data from on S3\n",
    "from noisepy.seis.io.plotting_modules import plot_substack_cc\n",
    "\n",
    "from noisepy.monitoring.monitoring_utils import *     # modules for monitoring utils\n",
    "from noisepy.monitoring.monitoring_methods import stretching\n",
    "from noisepy.monitoring.attenuation_utils import *    # modules for attenuation monitoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "path = os.path.expanduser(\"./\") # for local runs\n",
    "\n",
    "MAX_MEM = 4\n",
    "\n",
    "os.makedirs(path,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(2019, 1, 1, tzinfo=timezone.utc)\n",
    "end_date = datetime(2019, 1, 31, tzinfo=timezone.utc)\n",
    "print(start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config parameters of ccstore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigParameters() # default config parameters which can be customized\n",
    "\n",
    "config.start_date = start_date\n",
    "config.end_date = end_date\n",
    "\n",
    "config.samp_freq= 20    # (int) Sampling rate in Hz of desired processing (it can be different than the data sampling rate)\n",
    "config.cc_len= 600      # (int) basic unit of data length for fft (sec)\n",
    "    # criteria for data selection\n",
    "config.ncomp = 3        # 1 or 3 component data (needed to decide whether do rotation)\n",
    "\n",
    "\n",
    "config.acorr_only = True   # only perform auto-correlation or not\n",
    "config.xcorr_only = False  # only perform cross-correlation or not\n",
    "\n",
    "\n",
    "config.lamin = 31       # min latitude\n",
    "config.lamax = 42       # max latitude\n",
    "config.lomin = -124     # min longitude\n",
    "config.lomax = -115     # max longitude\n",
    "config.net_list = [\"CI\"] # network codes\n",
    "config.stations = [\"LJR\"] # station names, e.g. [\"LJR\",\"DLA\",\"LAF\"]\n",
    "\n",
    " # pre-processing parameters\n",
    "config.step= 600  # (int) overlapping between each cc_len (sec)\n",
    "config.stationxml= False  # station.XML file used to remove instrument response for SAC/miniseed data\n",
    "config.rm_resp= RmResp.INV  # select 'no' to not remove response and use 'inv' if you use the stationXML,'spectrum',\n",
    "config.freqmin = 0.05\n",
    "config.freqmax = 8.0\n",
    "config.max_over_std  = 10  # threshold to remove window of bad signals: set it to 10*9 if prefer not to remove them\n",
    "\n",
    "# TEMPORAL and SPECTRAL NORMALISATION\n",
    "config.freq_norm= FreqNorm.RMA  # choose between \"rma\" for a soft whitenning or \"no\" for no whitening. Pure whitening is not implemented correctly at this point.\n",
    "config.smoothspect_N = 10  # moving window length to smooth spectrum amplitude (points)\n",
    "    # here, choose smoothspect_N for the case of a strict whitening (e.g., phase_only)\n",
    "\n",
    "config.time_norm = TimeNorm.ONE_BIT  # 'no' for no normalization, or 'rma', 'one_bit' for normalization in time domain,\n",
    "    # TODO: change time_norm option from \"no\" to \"None\"\n",
    "config.smooth_N= 10  # moving window length for time domain normalization if selected (points)\n",
    "\n",
    "config.cc_method= CCMethod.XCORR  # 'xcorr' for pure cross correlation OR 'deconv' for deconvolution;\n",
    "    # FOR \"COHERENCY\" PLEASE set freq_norm to \"rma\", time_norm to \"no\" and cc_method to \"xcorr\"\n",
    "config.stack_method=StackMethod.ALL\n",
    "# OUTPUTS:\n",
    "num_stack=24\n",
    "config.substack = True  # True = smaller stacks within the time chunk. False: it will stack over inc_hours\n",
    "config.substack_len = num_stack * config.cc_len  # how long to stack over (for monitoring purpose): need to be multiples of cc_len\n",
    "    # if substack=True, substack_len=2*cc_len, then you pre-stack every 2 correlation windows.\n",
    "    # for instance: substack=True, substack_len=cc_len means that you keep ALL of the correlations\n",
    "\n",
    "config.maxlag= 60  # lags of cross-correlation to save (sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Cross correlate.\n",
    "\n",
    "This step will read data from S3, cross correlate, store the xcorrs on a local CCStore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 paths for raw data and stationXML\n",
    "S3_STORAGE_OPTIONS = {\"s3\": {\"anon\": True}} # S3 storage options\n",
    "S3_DATA = \"s3://scedc-pds/continuous_waveforms/\" # Continuous waveform data\n",
    "S3_STATION_XML = \"s3://scedc-pds/FDSNstationXML/CI/\"    # StationXML files for CI network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 data store\n",
    "timerange=DateTimeRange(config.start_date, config.end_date)\n",
    "catalog = XMLStationChannelCatalog(S3_STATION_XML, storage_options=S3_STORAGE_OPTIONS) # Station catalog\n",
    "raw_store = SCEDCS3DataStore(S3_DATA, catalog, channel_filter(config.net_list, config.stations, [\"BHE\", \"BHN\", \"BHZ\", \"HHE\", \"HHN\", \"HHZ\"]), \\\n",
    "                             timerange, storage_options=S3_STORAGE_OPTIONS) # Store for reading raw data from S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CC store \n",
    "cc_data_path = os.path.join(path, \"CCF_ASDF\")\n",
    "cc_store=ASDFCCStore(cc_data_path)\n",
    "\n",
    "# For this tutorial make sure the previous run is empty\n",
    "os.system(f\"rm -rf {cc_data_path}\")\n",
    "# Cross-correlation\n",
    "cross_correlate(raw_store, config, cc_store)\n",
    "\n",
    "# Save config parameters\n",
    "xcorr_config_fn='xcorr_config.yml'\n",
    "config.save_yaml(xcorr_config_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wwv1QCQhP_0Y"
   },
   "source": [
    "### Step 2: Read data from the NoisePy CCstore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step will read correlations from the NoisePy output ASDF files (ASDFCCStore).\n",
    "# --- local paths for CCs if CCs had been calculated ---\n",
    "# cc_data_path = os.path.join(path, \"CCF_ASDF\")\n",
    "# cc_store = ASDFCCStore(cc_data_path) # Store for writing CC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ua3T9j66dYHM"
   },
   "source": [
    "List out available station pairs. Plot a single set of the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1GiMvkhxR0U_eI1ZycRhG2IILJ6m25V6r"
    },
    "executionInfo": {
     "elapsed": 16988,
     "status": "ok",
     "timestamp": 1685658547570,
     "user": {
      "displayName": "Kuan-Fu Feng",
      "userId": "10709727719882205429"
     },
     "user_tz": 420
    },
    "id": "pWcrfWO8W1tH",
    "outputId": "450e13f5-bc11-4e8e-ebcf-507a3a5438db"
   },
   "outputs": [],
   "source": [
    "pairs_all = cc_store.get_station_pairs()\n",
    "stations = set(pair[0] for pair in pairs_all)\n",
    "print('pairs: ',pairs_all)\n",
    "print('stations: ', stations)\n",
    "\n",
    "src=\"CI.LJR\"\n",
    "rec=\"CI.LJR\"\n",
    "timespans = cc_store.get_timespans(src,rec)\n",
    "print(timespans)\n",
    "plot_substack_cc(cc_store, timespans[0], 0.1, 1, config.maxlag, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMeH9BslQSSJ"
   },
   "source": [
    "### Step 3: Look at invidual traces and make dv/v measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vO2FYNuccwM8"
   },
   "source": [
    "The config parameters for time-lapse seismic velocity measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1687294943700,
     "user": {
      "displayName": "Kuan-Fu Feng",
      "userId": "10709727719882205429"
     },
     "user_tz": 420
    },
    "id": "aiww1cVeczTu"
   },
   "outputs": [],
   "source": [
    "config_monito = ConfigParameters_monitoring() # default config parameters which can be customized\n",
    "\n",
    "# --- parameters for measuring velocity changes ---\n",
    "# pre-defined group velocity to window direct and code waves\n",
    "config_monito.vmin = 2.0  # minimum velocity of the direct waves -> start of the coda window\n",
    "config_monito.lwin = 20.0  # window length in sec for the coda waves\n",
    "\n",
    "# basic parameters\n",
    "config_monito.freq = [0.25, 0.5, 1.0]  # targeted frequency band for waveform monitoring\n",
    "nfreq = len(config_monito.freq) - 1\n",
    "config_monito.onelag = False  # make measurement one one lag or two\n",
    "config_monito.norm_flag = True  # whether to normalize the cross-correlation waveforms\n",
    "config_monito.do_stretch = True  # use strecthing method or not\n",
    "\n",
    "# parameters for stretching method\n",
    "config_monito.epsilon = 0.02  # limit for dv/v (in decimal)\n",
    "config_monito.nbtrial = 50  # number of increment of dt [-epsilon,epsilon] for the streching\n",
    "\n",
    "# coda window \n",
    "config_monito.coda_tbeg = 2.0  # begin time (sec) of the coda window in lag time\n",
    "config_monito.coda_tend = 8.0  # end time (sec) of the coda window in lag time\n",
    "\n",
    "# --- parameters for measuring attenuation ---\n",
    "config_monito.smooth_winlen = 10.0  # smoothing window length\n",
    "config_monito.cvel = 2.6  # Rayleigh wave velocities over the freqency bands\n",
    "config_monito.atten_tbeg = 2.0\n",
    "config_monito.atten_tend = 10.0\n",
    "config_monito.intb_interval_base=0.01 # interval base of intrinsic absorption parameter for a grid-searching process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a station pair for further measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1687294824784,
     "user": {
      "displayName": "Kuan-Fu Feng",
      "userId": "10709727719882205429"
     },
     "user_tz": 420
    },
    "id": "8Z9UJdtW3e4z",
    "outputId": "78327126-44a1-4477-8f60-3ce72f55f560"
   },
   "outputs": [],
   "source": [
    "sta_pair = pairs_all[0]\n",
    "src_sta = src \n",
    "rec_sta = rec \n",
    "timespans = cc_store.get_timespans(src,rec)\n",
    "print(src_sta,rec_sta)\n",
    "print(timespans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qymmNSUxIL2"
   },
   "source": [
    "Calculate and define the size of the data array : number of windows vs number of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1687294830026,
     "user": {
      "displayName": "Kuan-Fu Feng",
      "userId": "10709727719882205429"
     },
     "user_tz": 420
    },
    "id": "LYKq2PPqw79k",
    "outputId": "c00f5537-233a-492c-9984-998c639bde35"
   },
   "outputs": [],
   "source": [
    "# calculate the number of segments\n",
    "num_chunk = len(timespans)\n",
    "#num_segmts, npts_segmt = calc_segments(config, len(timespans)*config.ncomp**2, MAX_MEM)\n",
    "num_segmts, npts_one_segmt = calc_segments(config, len(timespans), MAX_MEM)\n",
    "print(f\"there are \",num_segmts,\" segments/windows and \",npts_one_segmt,\" points in each segments and overall\",num_chunk,\" number of time chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare arrays for reading in correlation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1687294831373,
     "user": {
      "displayName": "Kuan-Fu Feng",
      "userId": "10709727719882205429"
     },
     "user_tz": 420
    },
    "id": "Ei74lZsw3nat",
    "outputId": "a2465a7c-abf5-4bad-a53c-163a506aeaa2"
   },
   "outputs": [],
   "source": [
    "nccomp=config.ncomp**2\n",
    "cc_array = np.zeros((nccomp*num_chunk * num_segmts, npts_one_segmt), dtype=np.float32)\n",
    "cc_time  = np.zeros( nccomp*num_chunk * num_segmts, dtype=np.float32)\n",
    "cc_ngood = np.zeros( nccomp*num_chunk * num_segmts, dtype=np.int16)\n",
    "cc_comp  = np.chararray(nccomp*num_chunk * num_segmts, itemsize=2, unicode=True)\n",
    "print(cc_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data from ASDFCCStore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1687294834789,
     "user": {
      "displayName": "Kuan-Fu Feng",
      "userId": "10709727719882205429"
     },
     "user_tz": 420
    },
    "id": "o0qTJeV7yL3n",
    "outputId": "ced1dd59-c25c-40e0-9d89-4a8bc26a6bff"
   },
   "outputs": [],
   "source": [
    "iseg = 0\n",
    "print(\"timespans: \",timespans)\n",
    "print(\"station pair: \",sta_pair)\n",
    "for ts in timespans:\n",
    "    # read data and parameter matrix\n",
    "    src_chan, rec_chan = sta_pair\n",
    "    # load the n-component data, which is in order in the ASDFCCStore\n",
    "    ch_pairs = cc_store.read(ts, src_sta, rec_sta)\n",
    "    #print(ch_pairs)\n",
    "    for ch_pair in ch_pairs:\n",
    "        src_cha, rec_cha, params, all_data = ch_pair.src, ch_pair.rec, ch_pair.parameters, ch_pair.data\n",
    "        try:\n",
    "             \n",
    "            dist, tgood, ttime = (params[p] for p in [\"dist\", \"ngood\", \"time\"])\n",
    "            comp, dt, maxlag = (params[p] for p in [ \"comp\",\"dt\", \"maxlag\"])\n",
    "            tcmp1=str(comp)[0]\n",
    "            tcmp2=str(comp)[1]\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"continue! something wrong with {src_sta}_{rec_sta}/{src_cha}_{rec_cha}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if config.substack:\n",
    "            for ii in range(all_data.shape[0]):\n",
    "                cc_array[iseg] = all_data[ii]\n",
    "                cc_time[iseg] = ttime[ii]\n",
    "                cc_ngood[iseg] = tgood[ii]\n",
    "                cc_comp[iseg] = tcmp1 + tcmp2\n",
    "                iseg += 1\n",
    "        else:\n",
    "            cc_array[iseg] = all_data\n",
    "            cc_time[iseg] = ttime\n",
    "            cc_ngood[iseg] = tgood\n",
    "            cc_comp[iseg] = tcmp1 + tcmp2\n",
    "            iseg += 1\n",
    "            \n",
    "print(len(timespans),iseg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Df9aTFCa6hW4"
   },
   "source": [
    "Once the data is stored in memory, we follow these steps:\n",
    "* bandpass the data in a given frequency band,\n",
    "* stack to get a reference,\n",
    "* measure dv/v, save it into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "executionInfo": {
     "elapsed": 2084,
     "status": "ok",
     "timestamp": 1687294963986,
     "user": {
      "displayName": "Kuan-Fu Feng",
      "userId": "10709727719882205429"
     },
     "user_tz": 420
    },
    "id": "IhFhv4qQ6nmg",
    "outputId": "d0b3a485-21c5-4771-b2a8-7789491d3e69"
   },
   "outputs": [],
   "source": [
    "# in single-station cross-component case : enz_system = [ \"EN\", \"EZ\", \"NZ\"]\n",
    "freq1=config_monito.freq[0]\n",
    "freq2=config_monito.freq[1]\n",
    "dt=1/config.samp_freq\n",
    "\n",
    "## Choose a targeted component\n",
    "comp = \"EN\"\n",
    "\n",
    "# -- select only the data from the same cross-component cross correlations\n",
    "# -- and that have sufficiently good windows\n",
    "indx = np.where( (cc_comp.lower() == comp.lower()) & cc_ngood==1 )[0]\n",
    "nwin = len(indx)  # number of windows to stack.\n",
    "print(\"There are %d window in total for stacking\"%nwin,\" (good signal windows)\")\n",
    "\n",
    "# bandpass filter the data.\n",
    "tcur = np.zeros(shape=(len(indx),npts_one_segmt))\n",
    "for i in range(len(indx)):\n",
    "  tcur[i,:]=bandpass(cc_array[indx[i]], freq1, freq2, int(1 / dt), corners=4, zerophase=True)\n",
    "\n",
    "# output stacked data\n",
    "(\n",
    "    cc_final,\n",
    "    ngood_final,\n",
    "    stamps_final,\n",
    "    tref,\n",
    "    allstacks2,\n",
    "    allstacks3,\n",
    "    nstacks,\n",
    ") = noise_module.stacking(tcur, cc_time[indx], cc_ngood[indx], config)\n",
    "\n",
    "# Plot\n",
    "fig,ax=plt.subplots(3,1)\n",
    "ax[0].imshow(tcur,extent=[-config.maxlag,config.maxlag,iseg,0],aspect='auto',vmin=-0.001,vmax=0.001)\n",
    "ax[0].set_title(comp)\n",
    "ax[0].set_xlabel('Lag-time (sec)')\n",
    "ax[0].set_ylabel('Window number')\n",
    "\n",
    "ax[1].set_xlim(-config.maxlag,config.maxlag)\n",
    "ax[1].plot(np.arange(-config.maxlag,config.maxlag+dt,dt),tref);ax[1].grid(True)\n",
    "ax[1].set_title('Reference function')\n",
    "ax[1].set_xlabel('Lag-time (sec)')\n",
    "ax[1].set_ylabel('Amplitude')\n",
    "\n",
    "ax[2].plot(ngood_final,'.-');ax[2].grid(True)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Beu7gTaNgM6z"
   },
   "source": [
    "First, we will explore the stability of the correlations with respect to the reference (correlation coefficient), using the coda window of the config_monito parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the window index for positive and negative lag time\n",
    "pwin_indx, nwin_indx = window_indx_def(npts_one_segmt, config_monito.coda_tbeg, config_monito.coda_tend, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 717,
     "status": "ok",
     "timestamp": 1687294975487,
     "user": {
      "displayName": "Kuan-Fu Feng",
      "userId": "10709727719882205429"
     },
     "user_tz": 420
    },
    "id": "VFcmHuxDlBFZ",
    "outputId": "cfa1babc-8456-4dbb-8489-6ac61ee45a98"
   },
   "outputs": [],
   "source": [
    "# Calculate the correlation coefficient between the coda and the reference coda\n",
    "pcor_cc = np.zeros(shape=(nwin), dtype=np.float32)\n",
    "ncor_cc = np.zeros(shape=(nwin), dtype=np.float32)\n",
    "for i in range(nwin):\n",
    "  pcor_cc[i] = np.corrcoef(tref[pwin_indx], tcur[i, pwin_indx])[0, 1]\n",
    "  ncor_cc[i] = np.corrcoef(tref[nwin_indx], tcur[i, nwin_indx])[0, 1]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,2));plt.grid(True)\n",
    "plt.plot(pcor_cc, '.-', label='positive lag time')\n",
    "plt.plot(ncor_cc, '.-', label='negative lag time')\n",
    "plt.title('Correlation coefficient to the reference')\n",
    "plt.ylabel('Correlation coefficient')\n",
    "plt.xlabel('Window number')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNQyfNVRlaVr"
   },
   "source": [
    "Next, measuring dv/v. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 174,
     "status": "ok",
     "timestamp": 1687294989315,
     "user": {
      "displayName": "Kuan-Fu Feng",
      "userId": "10709727719882205429"
     },
     "user_tz": 420
    },
    "id": "Wk1gdj7AlyR8"
   },
   "outputs": [],
   "source": [
    "# initializing arrays\n",
    "dvv_stretch = np.zeros(shape=(nwin, 4), dtype=np.float32)\n",
    "\n",
    "# define the parameters for stretching\n",
    "para=dict()\n",
    "para[\"freq\"] = [freq1, freq2]\n",
    "para[\"twin\"] = [config_monito.coda_tbeg, config_monito.coda_tend]\n",
    "para[\"dt\"] = dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring dv/v on one component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 8726,
     "status": "ok",
     "timestamp": 1687295000816,
     "user": {
      "displayName": "Kuan-Fu Feng",
      "userId": "10709727719882205429"
     },
     "user_tz": 420
    },
    "id": "SxKJZMNr_4v1",
    "outputId": "d9ca3c8f-0256-45d1-f2e1-812d89e80059"
   },
   "outputs": [],
   "source": [
    "\n",
    "for ii in range(nwin):\n",
    "    # casual and acasual lags for both ref and cur waveforms\n",
    "    pcur = tcur[ii, pwin_indx]\n",
    "    ncur = tcur[ii, nwin_indx]\n",
    "    pref = tref[pwin_indx]\n",
    "    nref = tref[nwin_indx]\n",
    "    # functions working in time domain\n",
    "    if config_monito.do_stretch:\n",
    "        (\n",
    "            dvv_stretch[ii, 0],\n",
    "            dvv_stretch[ii, 1],\n",
    "            cc,\n",
    "            cdp,\n",
    "        ) = stretching(pref, pcur, config_monito.epsilon, config_monito.nbtrial, para)\n",
    "        (\n",
    "            dvv_stretch[ii, 2],\n",
    "            dvv_stretch[ii, 3],\n",
    "            cc,\n",
    "            cdp,\n",
    "        ) = stretching(nref, ncur, config_monito.epsilon, config_monito.nbtrial, para)\n",
    "plt.figure(figsize=(8,2))\n",
    "plt.plot(dvv_stretch);plt.grid(True)\n",
    "plt.legend(('dvv_positive-lag','error_positive-lag','dvv_negative-lag','error_negative-lag'),loc='upper right', bbox_to_anchor=(1.35,1))\n",
    "plt.title('Estimated dv/v and error')\n",
    "plt.xlabel('Window number')\n",
    "plt.ylabel('%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Measure dv/v on all cross-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_indx=86400//config.substack_len\n",
    "\n",
    "# select the data from the three cross-component correlations\n",
    "# that have sufficiently good windows\n",
    "enz_system = [ \"EN\", \"EZ\", \"NZ\"]\n",
    "comp = enz_system\n",
    "indx0 = np.where( (cc_comp.lower() == comp[0].lower()) & cc_ngood==1)[0]\n",
    "indx1 = np.where( (cc_comp.lower() == comp[1].lower()) & cc_ngood==1)[0]\n",
    "indx2 = np.where( (cc_comp.lower() == comp[2].lower()) & cc_ngood==1)[0]\n",
    "indx=np.intersect1d(np.intersect1d(indx0, indx1-(1*num_indx)),indx2-(3*num_indx))\n",
    "nwin=len(indx)\n",
    "print(\"Update the window number for the used components :\", nwin)\n",
    "\n",
    "# print(comp[0].lower(),indx0)\n",
    "# print(comp[1].lower(),indx1)\n",
    "# print(comp[2].lower(),indx2)\n",
    "#print(\"Final common indx between multiple components: \\n\",indx)\n",
    "\n",
    "indx_all=np.zeros(shape=(3,nwin),dtype=np.integer)\n",
    "indx_all[0]=indx\n",
    "indx_all[1]=indx+(1*num_indx)\n",
    "indx_all[2]=indx+(3*num_indx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing arrays again for multiple cross-component pairs\n",
    "dvv_stretch = np.zeros(shape=(nwin, 4), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( src_sta, rec_sta, nwin)\n",
    "nccomp=len(enz_system)\n",
    "\n",
    "# initializing arrays\n",
    "all_dvv= np.zeros(shape=(nccomp, nwin), dtype=np.float32)\n",
    "all_err= np.zeros(shape=(nccomp, nwin), dtype=np.float32)\n",
    "results_dvv= np.zeros(shape=(nwin), dtype=np.float32)\n",
    "results_err= np.zeros(shape=(nwin), dtype=np.float32)\n",
    "   \n",
    "for icomp in range(0,nccomp):\n",
    "    comp = enz_system[icomp]   \n",
    "\n",
    "    indx=indx_all[icomp]\n",
    "\n",
    "    # bandpass filter the data.\n",
    "    tcur = np.zeros(shape=(len(indx),npts_one_segmt))\n",
    "    for i in range(len(indx)):\n",
    "      tcur[i,:]=bandpass(cc_array[indx[i]], freq1, freq2, int(1 / dt), corners=4, zerophase=True)\n",
    "    \n",
    "    # output stacked data\n",
    "    (\n",
    "        cc_final,\n",
    "        ngood_final,\n",
    "        stamps_final,\n",
    "        tref,\n",
    "        allstacks2,\n",
    "        allstacks3,\n",
    "        nstacks,\n",
    "    ) = noise_module.stacking(tcur, cc_time[indx], cc_ngood[indx], config)\n",
    "    \n",
    "    for ii in range(nwin):\n",
    "        # casual and acasual lags for both ref and cur waveforms\n",
    "        pcur = tcur[ii, pwin_indx]\n",
    "        ncur = tcur[ii, nwin_indx]\n",
    "        pref = tref[pwin_indx]\n",
    "        nref = tref[nwin_indx]\n",
    "        # functions working in time domain\n",
    "        if config_monito.do_stretch:\n",
    "            (\n",
    "                dvv_stretch[ii, 0],\n",
    "                dvv_stretch[ii, 1],\n",
    "                cc,\n",
    "                cdp,\n",
    "            ) = stretching(pref, pcur, config_monito.epsilon, config_monito.nbtrial, para)\n",
    "            (\n",
    "                dvv_stretch[ii, 2],\n",
    "                dvv_stretch[ii, 3],\n",
    "                cc,\n",
    "                cdp,\n",
    "            ) = stretching(nref, ncur, config_monito.epsilon, config_monito.nbtrial, para)\n",
    "    all_dvv[icomp]=(dvv_stretch[:, 0]+dvv_stretch[:, 2])/2.0\n",
    "    all_err[icomp]=np.sqrt(dvv_stretch[:, 1]**2+dvv_stretch[:, 3]**2)\n",
    "    print('component: ',comp,' completed. ')\n",
    "    results_dvv+=all_dvv[icomp]\n",
    "    results_err+=all_err[icomp]**2\n",
    "results_dvv=results_dvv/nccomp\n",
    "results_err=np.sqrt(results_err)\n",
    "print(all_dvv.shape, results_dvv.shape, )\n",
    "nwin=len(results_dvv)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(2,2,figsize=(12,4))\n",
    "ax[0,0].plot(all_dvv.T)\n",
    "ax[0,0].legend(enz_system, loc='upper right', bbox_to_anchor=(1.15,1))\n",
    "ax[0,0].grid(True)\n",
    "ax[0,0].set_title('Estimated dv/v')\n",
    "ax[0,0].set_xlabel('Window number')\n",
    "ax[0,0].set_ylabel('%')\n",
    "\n",
    "ax[0,1].plot(all_err.T);ax[0,1].grid(True);#ax[0,1].set_ylim(0,100)\n",
    "ax[0,1].set_title('Estimated error')\n",
    "ax[0,1].set_xlabel('Window number')\n",
    "ax[0,1].set_ylabel('%')\n",
    "\n",
    "ax[1,0].plot(results_dvv.T);ax[1,0].grid(True)\n",
    "ax[1,0].set_title('Average dv/v')\n",
    "ax[1,0].set_xlabel('Window number')\n",
    "ax[1,0].set_ylabel('%')\n",
    "\n",
    "ax[1,1].plot(results_err.T);ax[1,1].grid(True)\n",
    "ax[1,1].set_title('Truncate error')\n",
    "ax[1,1].set_xlabel('Window number')\n",
    "ax[1,1].set_ylabel('%')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Measure attenuation parameter -- intrinsic absorption parameter b\n",
    "Preparing mean-squared values in time seires for measuring intrinsic parameter. We follow these steps:\n",
    "* Prepare smoothed mean-squared data (msv) in a given frequency band,\n",
    "* Get the average msv (msv_mean) from all components, and also the symmetric msv (fmsv_mean)\n",
    "* Measure intrinsic absorption parameter b (results_intb) and transfer it to intrinsic Q (Qi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "#enz_system = [\"EN\", \"EZ\", \"NZ\"]\n",
    "nccomp=len(enz_system)\n",
    "winlen=config_monito.smooth_winlen\n",
    "\n",
    "# Restore calendar time from cc_time array \n",
    "win_time=[]\n",
    "\n",
    "# initializing arrays \n",
    "tcur_temp1 = np.zeros(shape=(num_chunk*num_segmts, npts_one_segmt))\n",
    "msv=np.zeros((nccomp, num_chunk*num_segmts, npts_one_segmt))\n",
    "msv_temp=np.zeros((num_chunk*num_segmts, npts_one_segmt))\n",
    "\n",
    "# get all components average\n",
    "for icomp in range(0,nccomp):\n",
    "    comp = enz_system[icomp]\n",
    "    \n",
    "    # bandpass filter the data.\n",
    "    tcur_temp2 = np.zeros(shape=(len(indx),npts_one_segmt))\n",
    "    for i in range(len(indx)):\n",
    "        tcur_temp2[i,:]=bandpass(cc_array[indx[i]], freq1, freq2, int(1 / dt), corners=4, zerophase=True)\n",
    "        win_time.append(datetime.utcfromtimestamp(int(cc_time[indx[i]])).strftime(\"%Y-%m-%dT%H:%M\"))\n",
    "        #print(icomp, i , cc_time[indx[i]],datetime.utcfromtimestamp(int(cc_time[indx[i]])).strftime(\"%Y-%m-%dT%H:%M\"))\n",
    "        \n",
    "        para = { 'winlen':winlen, 'dt':dt , 'npts': len(tcur_temp2[i])}\n",
    "        msv[icomp,i]=get_smooth(tcur_temp2[i], para)\n",
    "        #print(tcur_temp.shape,msv[icomp].shape)\n",
    "\n",
    "    tcur_temp1[0:len(indx)]=tcur_temp1[0:len(indx)]+tcur_temp2\n",
    "    msv_temp=msv_temp+msv[icomp]\n",
    "\n",
    "tcur_avef = np.zeros(shape=(nwin, npts_one_segmt))\n",
    "msv_mean = np.zeros(shape=(nwin, npts_one_segmt))\n",
    "#print(nwin, tcur_avef.shape, msv.shape, msv_mean.shape)\n",
    "\n",
    "tcur_avef = tcur_temp1[:nwin,:]/nccomp\n",
    "msv_mean = msv_temp[:nwin,:]/nccomp\n",
    "msv_mean = msv_mean/np.max(msv_mean)\n",
    "del  tcur_temp1, tcur_temp2, msv_temp \n",
    "\n",
    "fig,ax=plt.subplots(2,1)\n",
    "ax[0].imshow(tcur_avef, extent=[-config.maxlag,config.maxlag,nwin,0],aspect='auto',vmin=-0.001,vmax=0.001)\n",
    "ax[0].set_title(str(nccomp)+\"-component average\")\n",
    "ax[0].set_ylabel('Window number')\n",
    "ax[0].set_xlabel('Lag-time (sec)')\n",
    "ax[1].imshow(msv_mean, extent=[-config.maxlag,config.maxlag,nwin,0],aspect='auto', norm=LogNorm(vmin=0.00001, vmax=1))\n",
    "ax[1].set_title(str(nccomp)+'-component averaged Mean-squared value')\n",
    "ax[1].set_xlabel('Lag-time (sec)')\n",
    "ax[1].set_ylabel('Window number')\n",
    "plt.tight_layout()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_npts=(npts_one_segmt-1)//2\n",
    "fmsv_mean=np.zeros((nwin,2,half_npts+1))\n",
    "\n",
    "for ntw in range(nwin):\n",
    "    sym=get_symmetric(msv_mean[ntw],half_npts)\n",
    "    fmsv_mean[ntw][0]=np.arange(0,config.maxlag+dt,dt)\n",
    "    fmsv_mean[ntw][1]=sym\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for getting the sum of squared residuals (SSR) between observed energy densities (Eobs) and synthesized energy densities (Esyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twinbe=np.ndarray((1,1,2))\n",
    "twinbe[0,0,0]=config_monito.atten_tbeg\n",
    "twinbe[0,0,1]=config_monito.atten_tend\n",
    "\n",
    "cvel=config_monito.cvel # Rayleigh wave velocities over the freqency bands\n",
    "vdist=np.zeros((1))     # station distance\n",
    "mfpx=np.zeros(1)        # mean_free_path search array\n",
    "intby=np.zeros(80)      # intrinsic_b search array\n",
    "config_monito.intb_interval_base=0.01 # interval base for a grid-searching process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the sum of squared residuals (SSR) between Eobs and Esyn  \n",
    "SSR_final=np.zeros((len(mfpx),len(intby)))\n",
    "SSR=np.zeros((nwin,1,len(mfpx),len(intby)))\n",
    "\n",
    "for ntw in range(nwin):\n",
    "    data=np.zeros(shape=(1,2,half_npts+1))\n",
    "    data[0,:,:]=fmsv_mean[ntw]\n",
    "    #print(data.shape,fmsv_mean[ntw].shape)\n",
    "    # parameters for getting the sum of squared residuals (SSR) between Eobs and Esyn \n",
    "    para={ 'fb':0 , 'vdist':vdist, 'npts':npts_one_segmt, 'dt':dt, 'cvel':cvel, \\\n",
    "        'mfp':mfpx, 'intb':intby,'twin':twinbe, 'fmsv':data }\n",
    "    # call function get_SSR\n",
    "    SSR_final, mfpx, intby = get_SSR(1, para )\n",
    "\n",
    "    SSR[ntw][0]=SSR_final\n",
    "print(SSR.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fitting_result(mean_free,intrinsic_b,tt,Eobs,Esyn,fname,dist,twind,fmin,fmax,win_num):\n",
    "    plt.figure(figsize=(6,2))\n",
    "    plt.yscale('log', base=10)\n",
    "\n",
    "    pymax=np.max(Eobs[:-2]*5)\n",
    "    pymin=10**(-3)\n",
    "    print( pymin , pymax )\n",
    "    plt.ylim( pymin , pymax )\n",
    "    plt.plot( tt, Eobs, \"k-\", linewidth=1)\n",
    "    plt.plot( tt, Esyn, \"b--\", linewidth=1)\n",
    "    plt.plot([twind[0],twind[0],twind[-1],twind[-1],twind[0]],[pymin, pymax,pymax,pymin,pymin],\"r\", linewidth=2)\n",
    "\n",
    "    plt.title(\"%s @%4.2f-%4.2f Hz, intrinsic b: %.2f, Window no. %d\" \\\n",
    "            % ( fname,fmin,fmax,intrinsic_b, win_num))\n",
    "    plt.xlabel(\"Lag time (sec)\")\n",
    "    plt.ylabel(\"Energy density Amp\")\n",
    "    plt.tight_layout()   \n",
    "    plt.show()\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting optimal fit in grid-searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the optimal value from the SSR\n",
    "result_intb=np.zeros((nwin,1))\n",
    "result_mfp=np.zeros((nwin, 1))\n",
    "\n",
    "Eobs=np.ndarray((1,half_npts))\n",
    "Esyn=np.ndarray((1,half_npts))\n",
    "aa=0\n",
    "r=np.take(vdist[aa],0) \n",
    "\n",
    "fmin=freq1\n",
    "fmax=freq2\n",
    "wfcen=2.0*np.pi*((freq1+freq2)/2.0)\n",
    "\n",
    "for ntw in range(nwin):\n",
    "\n",
    "    data=np.zeros(shape=(1,2,half_npts+1))\n",
    "    data[0,:,:]=fmsv_mean[ntw]\n",
    "    # parameters for getting optimal value from the sum of squared residuals (SSR) between Eobs and Esyn \n",
    "    para={ 'fb':0, 'fmin':fmin, 'fmax':fmax, 'vdist':vdist, 'npts':npts_one_segmt, 'dt':dt, 'cvel':cvel, 'filenum':aa, \\\n",
    "        'mfp':mfpx, 'intb':intby, 'twin':twinbe, 'fmsv':data, 'SSR':SSR[ntw] , 'sta':sta_pair}\n",
    "    # call function get_optimal\n",
    "    result_intb[ntw], result_mfp[ntw], Eobs, Esyn = get_optimal_Esyn(1,para)\n",
    "    # plotting fitting results\n",
    "    if ntw == 32:\n",
    "        plot_fitting_result(result_mfp,result_intb[ntw],data[0,0,:], \n",
    "                    Eobs,Esyn,sta_pair,vdist[0],twinbe[0][0],fmin,fmax,ntw)\n",
    "    \n",
    "intQ=np.zeros((nwin,1)) \n",
    "intQ=wfcen/result_intb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(2,1,figsize=(6,4))\n",
    "ax[0].plot(result_intb, label='intrinsic b')\n",
    "ax[0].grid(True)\n",
    "ax[0].set_title('Estimated intrinsic absorption parameter b')\n",
    "ax[0].set_xlabel('Window number')\n",
    "ax[0].set_ylabel('b')\n",
    "\n",
    "ax[1].plot(intQ, label='Q')\n",
    "ax[1].set_yscale(\"log\")\n",
    "ax[1].grid(True)\n",
    "ax[1].set_title('Estimated intrinsic Q')\n",
    "ax[1].set_xlabel('Window number')\n",
    "ax[1].set_ylabel('Q value')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save config parameters\n",
    "monito_config_fn='monito_config.yml'\n",
    "config_monito.save_yaml(monito_config_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Output results as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore calendar time from cc_time array \n",
    "#cal_time=win_time[:nwin]\n",
    "cal_time=win_time[:len(win_time)//3]\n",
    "print(len(cal_time),results_dvv.shape,result_intb[:,0].shape, intQ.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fieldnames = ['time', 'dvv','err','int_b','wfcen', 'Q']\n",
    "fcsv=\"Monitoring_output.csv\"\n",
    "data={\n",
    "'time': cal_time,\n",
    "'dvv':  results_dvv,\n",
    "'err':  results_err,\n",
    "'int_b': result_intb[:,0],\n",
    "'wfcen': np.full((nwin),wfcen),\n",
    "'Q': intQ[:,0],\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "df.to_csv(fcsv,columns=fieldnames,sep=',',index = None, header=True, float_format=\"%.4f\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "fig,ax=plt.subplots(4,1,figsize=(6,8))\n",
    "\n",
    "t=[datetime.strptime(d,'%Y-%m-%dT%H:%M').strftime('%Y-%m-%dT%H:%M') for d in cal_time]\n",
    "t=pd.to_datetime(t)\n",
    "\n",
    "ax[0].set_ylim(0,100)\n",
    "ax[0].plot_date(t, results_err, '.-', label='error of dv/v (%)')\n",
    "ax[0].set_title('Truncate estimated error')\n",
    "ax[0].set_ylabel('%')\n",
    "\n",
    "ax[1].plot_date(t, results_dvv, '.-', label='dv/v (%)')\n",
    "ax[1].set_title('Average dv/v')\n",
    "ax[1].set_ylabel('%')\n",
    "\n",
    "ax[2].plot_date(t, result_intb[:,0], '.-', label='intrinsic b')\n",
    "ax[2].set_title('Estimated intrinsic absorption parameter b')\n",
    "ax[2].set_ylabel('intrinsic b')\n",
    "\n",
    "ax[3].plot_date(t,intQ[:,0],'.-',  label='Q')\n",
    "ax[3].set_title('Estimated Q')\n",
    "ax[3].set_ylabel('Q value')\n",
    "ax[3].set_xlabel('Time')\n",
    "ax[3].set_yscale('log')\n",
    "for k in range(4):\n",
    "    ax[k].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%dT%H:%M'))\n",
    "    ax[k].set_xlim(np.datetime64(t[0]), np.datetime64(t[-1]))\n",
    "    ax[k].xaxis.set_major_locator(mdates.DayLocator(interval=7))\n",
    "    ax[k].tick_params('x',labelrotation=20)\n",
    "    ax[k].grid(True)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the output csv file on S3-bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_s3bucket=\"s3://YOUR_S3-bucket/\"\n",
    "\n",
    "command=\"aws s3 cp \"+fcsv+\" \"+my_s3bucket\n",
    "print(command)\n",
    "#os.system(command)\n",
    "\n",
    "command=\"aws s3 cp \"+xcorr_config_fn+\" \"+my_s3bucket\n",
    "print(command)\n",
    "#os.system(command) \n",
    "\n",
    "command=\"aws s3 cp \"+monito_config_fn+\" \"+my_s3bucket\n",
    "print(command)\n",
    "#os.system(command) \n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "colab": {
   "provenance": [
    {
     "file_id": "1e9VNPO9u5CJvrt97PMd5oYR0m957zUTL",
     "timestamp": 1685651705763
    },
    {
     "file_id": "https://github.com/mdenolle/NoisePy/blob/master/tutorials/get_started.ipynb",
     "timestamp": 1685564374770
    }
   ]
  },
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
